{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T16:40:30.078539Z",
     "start_time": "2025-04-06T16:40:14.127312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# === KHÔNG THAY ĐỔI (Imports cơ bản và thêm thư viện cho HTR) ===\n",
    "import os\n",
    "import math # === THÊM: Thêm math để tính toán output width nếu cần ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import sns # Không cần thiết cho HTR cơ bản\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models # <--- THAY ĐỔI: Thêm models\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import matplotlib.pyplot as plt # Thêm để vẽ đồ thị loss (tùy chọn)\n",
    "import json # Import json để lưu/tải map ký tự\n",
    "\n",
    "# === THÊM: Kiểm tra và cảnh báo tương thích checkpoint ===\n",
    "EXPECTED_ARCHITECTURE = \"EfficientNetB0_CRNN\" # Đặt tên cho kiến trúc mới"
   ],
   "id": "f04663922ccd9a9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T17:07:00.060501Z",
     "start_time": "2025-04-06T17:07:00.050535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Thiết lập đường dẫn) ===\n",
    "# Đường dẫn thư mục dữ liệu\n",
    "data_dir = r\"E:\\HANDS-VNOnDB\" # <--- KIỂM TRA LẠI ĐƯỜNG DẪN NÀY\n",
    "label_file_path = os.path.join(data_dir, \"reduced_normalized_InkData_word.csv\") # <--- File chứa cả ID và label text\n",
    "image_folder_original = os.path.join(data_dir, \"reduced_Processed_Images_Words\")\n",
    "\n",
    "# Thư mục lưu ảnh đã xử lý (resize)\n",
    "image_folder_processed = r\"D:\\HANDS-VNOnDB\\Processed_Images_Words_HTR\" "
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:07:01.237880Z",
     "start_time": "2025-04-06T17:07:01.220881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Chuẩn hóa file gán nhãn\n",
    "\n",
    "# def split_id(df, id_col=\"id\"):\n",
    "#     df[['document_id', 'line_id', 'word_id']] = df[id_col].str.rsplit('_', n=2, expand=True)\n",
    "#     return df.head()\n",
    "\n",
    "# print((pd.read_csv(os.path.join(data_dir, \"normalized_InkData_line.csv\"))))"
   ],
   "id": "42300f39aa46ee87",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:00:37.788564Z",
     "start_time": "2025-04-06T17:00:37.780564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TARGET_IMG_HEIGHT = 32\n",
    "TARGET_IMG_WIDTH = 384 "
   ],
   "id": "1740783711f78574",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:07:03.255529Z",
     "start_time": "2025-04-06T17:07:03.243531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_image_htr(image_path, target_size=(TARGET_IMG_WIDTH, TARGET_IMG_HEIGHT)):\n",
    "    \"\"\"Mở ảnh, chuyển grayscale, resize.\"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img_gray = img.convert('L')\n",
    "            img_resized = img_gray.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        return img_resized\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi mở hoặc xử lý ảnh {image_path}: {e}\")\n",
    "        return None"
   ],
   "id": "ca3d7a094f2fb46a",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:07:04.528518Z",
     "start_time": "2025-04-06T17:07:04.513514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_and_save_images_htr(input_folder, output_folder, target_size=(TARGET_IMG_WIDTH, TARGET_IMG_HEIGHT)):\n",
    "    \"\"\"Tiền xử lý và lưu ảnh vào thư mục mới.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(f\"Đã tạo thư mục: {output_folder}\")\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg'))]\n",
    "    print(f\"Tìm thấy {len(image_files)} ảnh trong {input_folder}\")\n",
    "\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "    error_count = 0\n",
    "    for img_file in tqdm(image_files, desc=\"Preprocessing images for HTR\", unit=\"image\"):\n",
    "        img_path = os.path.join(input_folder, img_file)\n",
    "        output_img_path = os.path.join(output_folder, img_file)\n",
    "\n",
    "        if not os.path.exists(output_img_path):\n",
    "            processed_img = preprocess_image_htr(img_path, target_size)\n",
    "            if processed_img:\n",
    "                try:\n",
    "                    processed_img.save(output_img_path)\n",
    "                    processed_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi khi lưu ảnh {output_img_path}: {e}\")\n",
    "                    error_count += 1\n",
    "            else:\n",
    "                 error_count += 1 # Lỗi trong hàm preprocess_image_htr\n",
    "        else:\n",
    "            skipped_count += 1\n",
    "\n",
    "    total_processed_or_skipped = processed_count + skipped_count\n",
    "    print(f\"Hoàn thành tiền xử lý:\")\n",
    "    print(f\"- Đã xử lý mới: {processed_count}\")\n",
    "    print(f\"- Bỏ qua (đã tồn tại): {skipped_count}\")\n",
    "    print(f\"- Lỗi: {error_count}\")\n",
    "    print(f\"- Tổng số ảnh trong thư mục output: {total_processed_or_skipped}\")\n",
    "    print(f\"Ảnh đã xử lý được lưu tại: {output_folder}\")"
   ],
   "id": "1331ea1f6a01dc93",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:07:08.046301Z",
     "start_time": "2025-04-06T17:07:06.308713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chạy tiền xử lý ảnh (chỉ chạy nếu thư mục processed chưa có hoặc muốn ghi đè)\n",
    "run_preprocessing = True # Đặt thành False nếu đã chạy và không muốn chạy lại\n",
    "if run_preprocessing:\n",
    "    process_and_save_images_htr(image_folder_original, image_folder_processed, target_size=(TARGET_IMG_WIDTH, TARGET_IMG_HEIGHT))\n",
    "else:\n",
    "    print(f\"Bỏ qua bước tiền xử lý ảnh, sử dụng ảnh tại: {image_folder_processed}\")\n",
    "    if not os.path.exists(image_folder_processed):\n",
    "        print(f\"CẢNH BÁO: Thư mục ảnh đã xử lý {image_folder_processed} không tồn tại nhưng run_preprocessing=False.\")\n",
    "        exit()\n"
   ],
   "id": "7d8b68ce2342949c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 33224 ảnh trong E:\\HANDS-VNOnDB\\reduced_Processed_Images_Words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images for HTR: 100%|██████████| 33224/33224 [00:01<00:00, 19605.06image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoàn thành tiền xử lý:\n",
      "- Đã xử lý mới: 0\n",
      "- Bỏ qua (đã tồn tại): 33224\n",
      "- Lỗi: 0\n",
      "- Tổng số ảnh trong thư mục output: 33224\n",
      "Ảnh đã xử lý được lưu tại: D:\\HANDS-VNOnDB\\Processed_Images_Words_HTR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:07:09.804083Z",
     "start_time": "2025-04-06T17:07:09.749572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI (Load nhãn TEXT thay vì ID) ===\n",
    "# Đọc file CSV chứa nhãn\n",
    "try:\n",
    "    labels_df = pd.read_csv(label_file_path)\n",
    "    print(f\"Đã đọc thành công file label: {label_file_path}\")\n",
    "    # print(\"5 dòng đầu tiên của labels_df:\")\n",
    "    # print(labels_df.head())\n",
    "    if 'label' not in labels_df.columns or 'id' not in labels_df.columns:\n",
    "        raise ValueError(\"File CSV phải chứa cột 'id' và 'label'.\")\n",
    "    # Xử lý giá trị NaN trong cột label (thay bằng chuỗi rỗng hoặc bỏ qua)\n",
    "    labels_df['label'] = labels_df['label'].fillna('')\n",
    "    print(f\"Số lượng dòng trong file label: {len(labels_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"LỖI khi đọc hoặc kiểm tra file CSV: {e}\")\n",
    "    exit()"
   ],
   "id": "f07e1eaf28983abe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã đọc thành công file label: E:\\HANDS-VNOnDB\\reduced_normalized_InkData_word.csv\n",
      "Số lượng dòng trong file label: 33224\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:07:12.236058Z",
     "start_time": "2025-04-06T17:07:12.229063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Hàm tải đường dẫn ảnh và nhãn TEXT, đảm bảo khớp ID và ảnh tồn tại\n",
    "def load_image_paths_and_text_labels(processed_image_folder, labels_df):\n",
    "    image_paths = []\n",
    "    text_labels = []\n",
    "    missing_images = 0\n",
    "    valid_ids_from_df = set(labels_df['id'])\n",
    "    processed_image_files = os.listdir(processed_image_folder)\n",
    "    processed_ids = set(os.path.splitext(f)[0] for f in processed_image_files if f.endswith(('.png', '.jpg')))\n",
    "\n",
    "    print(f\"Số ID hợp lệ từ CSV: {len(valid_ids_from_df)}\")\n",
    "    print(f\"Số ảnh tìm thấy trong thư mục đã xử lý: {len(processed_ids)}\")\n",
    "\n",
    "    # Lọc DataFrame để chỉ giữ lại các ID có ảnh tương ứng\n",
    "    labels_df_filtered = labels_df[labels_df['id'].isin(processed_ids)].copy()\n",
    "    print(f\"Số lượng mẫu sau khi lọc (có cả ảnh và label): {len(labels_df_filtered)}\")\n",
    "\n",
    "    # Tạo dictionary từ ID sang label text (từ DataFrame đã lọc)\n",
    "    id_to_label = pd.Series(labels_df_filtered.label.values, index=labels_df_filtered.id).to_dict()\n",
    "\n",
    "    # Lặp qua các ID đã lọc để tạo list cuối cùng\n",
    "    for img_id in tqdm(labels_df_filtered['id'], desc=\"Khớp ảnh và nhãn\"):\n",
    "        img_filename = f\"{img_id}.png\" # Hoặc .jpg nếu có\n",
    "        img_path = os.path.join(processed_image_folder, img_filename)\n",
    "        # Kiểm tra lại lần nữa (dù đã lọc)\n",
    "        if os.path.exists(img_path):\n",
    "            image_paths.append(img_path)\n",
    "            text_labels.append(id_to_label[img_id])\n",
    "        else:\n",
    "             missing_images += 1 # Không nên xảy ra nếu lọc đúng\n",
    "\n",
    "    if missing_images > 0:\n",
    "        print(f\"Cảnh báo: {missing_images} ảnh có trong df_filtered nhưng không tìm thấy file!\")\n",
    "\n",
    "    return image_paths, text_labels"
   ],
   "id": "b00c6339cd0d289f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:07:21.571829Z",
     "start_time": "2025-04-06T17:07:19.823524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tải dữ liệu\n",
    "all_image_paths, all_text_labels = load_image_paths_and_text_labels(image_folder_processed, labels_df)\n",
    "\n",
    "if not all_image_paths:\n",
    "    print(\"Lỗi: Không tải được ảnh hoặc nhãn nào. Kiểm tra lại đường dẫn và file.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Đã tải thành công {len(all_image_paths)} cặp ảnh-nhãn.\")\n",
    "print(\"Ví dụ 5 nhãn đầu tiên:\", all_text_labels[:5])"
   ],
   "id": "62395cacb5ef0d5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số ID hợp lệ từ CSV: 33224\n",
      "Số ảnh tìm thấy trong thư mục đã xử lý: 33224\n",
      "Số lượng mẫu sau khi lọc (có cả ảnh và label): 33224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Khớp ảnh và nhãn: 100%|██████████| 33224/33224 [00:01<00:00, 20488.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tải thành công 33224 cặp ảnh-nhãn.\n",
      "Ví dụ 5 nhãn đầu tiên: ['hội', 'Nhưng', 'những', 'kinh', 'cuộc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:07:53.086938Z",
     "start_time": "2025-04-06T17:07:52.982127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI (Chia Train/Test cho dữ liệu HTR) ===\n",
    "# Đường dẫn lưu file train/test sau khi chia\n",
    "train_csv_path = os.path.join(data_dir, \"train_htr_words.csv\")\n",
    "test_csv_path = os.path.join(data_dir, \"test_htr_words.csv\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_paths, X_test_paths, y_train_text, y_test_text = train_test_split(\n",
    "    all_image_paths, all_text_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Số lượng mẫu train: {len(X_train_paths)}\")\n",
    "print(f\"Số lượng mẫu test: {len(X_test_paths)}\")\n",
    "\n",
    "try:\n",
    "    # Tạo DataFrame và lưu train set\n",
    "    train_data_to_save = pd.DataFrame({'image_path': X_train_paths, 'label': y_train_text})\n",
    "    train_data_to_save.to_csv(train_csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"Đã lưu tập train vào: {train_csv_path}\")\n",
    "\n",
    "    # Tạo DataFrame và lưu test set\n",
    "    test_data_to_save = pd.DataFrame({'image_path': X_test_paths, 'label': y_test_text})\n",
    "    test_data_to_save.to_csv(test_csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"Đã lưu tập test vào: {test_csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi lưu file train/test CSV: {e}\")\n"
   ],
   "id": "53f46100bc1a5a22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng mẫu train: 26579\n",
      "Số lượng mẫu test: 6645\n",
      "Đã lưu tập train vào: E:\\HANDS-VNOnDB\\train_htr_words.csv\n",
      "Đã lưu tập test vào: E:\\HANDS-VNOnDB\\test_htr_words.csv\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:08:13.241062Z",
     "start_time": "2025-04-06T17:08:13.194008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI (Tạo bộ ký tự và mã hóa nhãn cho HTR) ===\n",
    "\n",
    "# Tìm tất cả các ký tự duy nhất từ tập train và test\n",
    "all_texts_for_vocab = y_train_text + y_test_text\n",
    "characters = set(char for text in all_texts_for_vocab for char in str(text))\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "# Thêm ký tự đặc biệt 'blank' cho CTC Loss (thường ở index 0)\n",
    "BLANK_TOKEN = '<blank>'\n",
    "if BLANK_TOKEN not in characters:\n",
    "    characters.insert(0, BLANK_TOKEN) # Đảm bảo blank ở vị trí 0\n",
    "\n",
    "print(f\"Tổng số ký tự (bao gồm blank): {len(characters)}\")\n",
    "# print(\"Bộ ký tự:\", \"\".join(characters)) # Có thể rất dài\n",
    "\n",
    "# Tạo từ điển ánh xạ\n",
    "char_to_int = {char: i for i, char in enumerate(characters)}\n",
    "int_to_char = {i: char for i, char in enumerate(characters)}\n",
    "\n",
    "# Số lượng lớp cho mô hình = số ký tự\n",
    "num_classes_htr = len(characters)\n",
    "print(f\"Số lớp đầu ra cho mô hình HTR: {num_classes_htr}\")\n",
    "\n",
    "# Hàm mã hóa text thành chuỗi số nguyên\n",
    "def encode_text(text, char_to_int_map):\n",
    "    return [char_to_int_map[char] for char in str(text) if char in char_to_int_map]\n",
    "\n",
    "# Mã hóa nhãn train và test\n",
    "y_train_encoded = [encode_text(text, char_to_int) for text in y_train_text]\n",
    "y_test_encoded = [encode_text(text, char_to_int) for text in y_test_text]\n",
    "\n",
    "# In thử vài mẫu đã mã hóa\n",
    "print(\"\\nVí dụ mã hóa:\")\n",
    "print(\"Nhãn gốc:\", y_train_text[0])\n",
    "print(\"Nhãn mã hóa:\", y_train_encoded[0])\n",
    "print(\"Giải mã lại:\", \"\".join([int_to_char[i] for i in y_train_encoded[0]]))"
   ],
   "id": "d836a8da784db0ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số ký tự (bao gồm blank): 144\n",
      "Số lớp đầu ra cho mô hình HTR: 144\n",
      "\n",
      "Ví dụ mã hóa:\n",
      "Nhãn gốc: xét\n",
      "Nhãn mã hóa: [57, 70, 54]\n",
      "Giải mã lại: xét\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:08:42.062509Z",
     "start_time": "2025-04-06T17:08:41.981893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- THÊM CODE LƯU FILE ĐÃ MÃ HÓA ---\n",
    "import json\n",
    "from tqdm import tqdm # Đảm bảo tqdm đã được import\n",
    "print(\"\\nBắt đầu lưu file đã mã hóa và bản đồ ký tự...\")\n",
    "\n",
    "# Định nghĩa đường dẫn file lưu (cùng thư mục với train/test csv)\n",
    "encoded_train_path = os.path.join(data_dir, \"encoded_train_word_labels.json\")\n",
    "encoded_test_path = os.path.join(data_dir, \"encoded_test_word_labels.json\")\n",
    "charmap_path = os.path.join(data_dir, \"character_map.json\")\n",
    "\n",
    "try:\n",
    "    # Lưu y_train_encoded\n",
    "    with open(encoded_train_path, 'w', encoding='utf-8') as f_train:\n",
    "        json.dump(y_train_encoded, f_train)\n",
    "    print(f\"Đã lưu nhãn train đã mã hóa vào: {encoded_train_path}\")\n",
    "\n",
    "    # Lưu y_test_encoded\n",
    "    with open(encoded_test_path, 'w', encoding='utf-8') as f_test:\n",
    "        json.dump(y_test_encoded, f_test)\n",
    "    print(f\"Đã lưu nhãn test đã mã hóa vào: {encoded_test_path}\")\n",
    "\n",
    "    # Lưu cả hai bản đồ ký tự vào một file\n",
    "    # Chuyển key của int_to_char thành string để tương thích JSON\n",
    "    int_to_char_str_keys = {str(k): v for k, v in int_to_char.items()}\n",
    "    char_maps = {\n",
    "        'char_to_int': char_to_int,\n",
    "        'int_to_char': int_to_char_str_keys # Lưu phiên bản key là string\n",
    "    }\n",
    "    with open(charmap_path, 'w', encoding='utf-8') as f_map:\n",
    "        # indent=4 để dễ đọc file JSON hơn\n",
    "        # ensure_ascii=False để lưu đúng ký tự tiếng Việt\n",
    "        json.dump(char_maps, f_map, ensure_ascii=False, indent=4)\n",
    "    print(f\"Đã lưu bản đồ ký tự vào: {charmap_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi lưu file JSON đã mã hóa: {e}\")\n",
    "# --- KẾT THÚC CODE LƯU FILE ---"
   ],
   "id": "b164a1ac6ab11e57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bắt đầu lưu file đã mã hóa và bản đồ ký tự...\n",
      "Đã lưu nhãn train đã mã hóa vào: E:\\HANDS-VNOnDB\\encoded_train_word_labels.json\n",
      "Đã lưu nhãn test đã mã hóa vào: E:\\HANDS-VNOnDB\\encoded_test_word_labels.json\n",
      "Đã lưu bản đồ ký tự vào: E:\\HANDS-VNOnDB\\character_map.json\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:09:11.012767Z",
     "start_time": "2025-04-06T17:09:10.614690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI: Tính toán CNN Output Width cho EfficientNet-B0 BỊ CẮT BỚT SỚM HƠN ===\n",
    "# Cần chạy cell này TRƯỚC khi định nghĩa collate_fn và model\n",
    "\n",
    "import traceback # Import traceback for more detailed error printing\n",
    "\n",
    "# --- Helper function để lấy phần CNN bị cắt bớt SỚM HƠN ---\n",
    "def get_truncated_efficientnet_features():\n",
    "    \"\"\"Tải EfficientNet-B0 và trả về phần features bị cắt bớt RẤT SỚM (ví dụ: tới block 2).\"\"\"\n",
    "    # Tải cấu trúc (weights=None để nhanh)\n",
    "    effnet_full_features = models.efficientnet_b0(weights=None).features\n",
    "    # Chọn các block bạn muốn giữ lại. Ví dụ: block 0 đến 2 (3 block đầu tiên)\n",
    "    # [:3] tương ứng với output của stage 2 (reduction factor 4)\n",
    "    truncated_cnn = nn.Sequential(*list(effnet_full_features[:3]))\n",
    "    return truncated_cnn\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def calculate_cnn_output_width(img_height, img_width):\n",
    "    \"\"\"\n",
    "    Ước tính chiều rộng và số kênh output của CNN EfficientNet-B0 ĐÃ BỊ CẮT BỚT SỚM.\n",
    "    \"\"\"\n",
    "    # Dự đoán fallback width và channels cho [:3]\n",
    "    cnn_output_w = img_width // 4 # Ước tính width = input_width / 4\n",
    "    cnn_output_c = 40 # Output channels của block 2 trong EffNetB0\n",
    "\n",
    "    # ... (Phần try-except-finally giữ nguyên logic, chỉ thay đổi hàm gọi) ...\n",
    "    effnet_features = None\n",
    "    dummy_input = None\n",
    "    output_features = None\n",
    "\n",
    "    try:\n",
    "        print(\"Xây dựng kiến trúc CNN bị cắt bớt SỚM HƠN (ví dụ: EffNetB0 features[:3])...\")\n",
    "        truncated_cnn = get_truncated_efficientnet_features() # Gọi hàm helper mới\n",
    "        truncated_cnn.eval()\n",
    "        print(\"Xây dựng CNN bị cắt bớt thành công.\")\n",
    "\n",
    "        dummy_input = torch.randn(1, 3, img_height, img_width)\n",
    "        print(f\"Tạo dummy input shape: {dummy_input.shape}\")\n",
    "\n",
    "        print(\"Đang chạy dummy input qua CNN bị cắt bớt...\")\n",
    "        with torch.no_grad():\n",
    "            output_features = truncated_cnn(dummy_input)\n",
    "        print(\"Chạy dummy input thành công.\")\n",
    "\n",
    "        cnn_output_c = output_features.shape[1]\n",
    "        cnn_output_w = output_features.shape[3]\n",
    "\n",
    "        print(f\"--- Tính toán Output CNN (Truncated[:3] EfficientNet-B0) ---\") # Cập nhật tiêu đề\n",
    "        print(f\"Input H={img_height}, W={img_width}\")\n",
    "        print(f\"Output shape after TRUNCATED[:3] features: [N, C, H, W] = {output_features.shape}\")\n",
    "        print(f\"===> Số kênh output của CNN (C_out): {cnn_output_c}\")\n",
    "        print(f\"===> Chiều rộng output của CNN (W_out / SeqLen for RNN): {cnn_output_w}\")\n",
    "        print(f\"---------------------------------------------------------\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # ... (Phần xử lý lỗi giữ nguyên) ...\n",
    "        print(f\"\\nLỖI khi chạy dummy input qua CNN bị cắt bớt SỚM: {e}\")\n",
    "        traceback.print_exc()\n",
    "        print(f\"===> Sử dụng giá trị mặc định dự đoán: W={cnn_output_w}, C={cnn_output_c}\")\n",
    "\n",
    "    finally:\n",
    "        # ... (Phần dọn dẹp giữ nguyên) ...\n",
    "         if truncated_cnn is not None: del truncated_cnn\n",
    "         if dummy_input is not None: del dummy_input\n",
    "         if output_features is not None: del output_features\n",
    "         gc.collect()\n",
    "         if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    # Return the calculated values\n",
    "    return cnn_output_w, cnn_output_c\n",
    "\n",
    "# --- Tính toán và gán giá trị toàn cục ---\n",
    "if 'TARGET_IMG_HEIGHT' not in globals() or 'TARGET_IMG_WIDTH' not in globals():\n",
    "     raise ValueError(\"TARGET_IMG_HEIGHT và TARGET_IMG_WIDTH chưa được định nghĩa!\")\n",
    "\n",
    "print(\"Bắt đầu tính toán CNN_OUTPUT_WIDTH và CNN_OUTPUT_CHANNELS cho CNN bị cắt bớt SỚM HƠN...\")\n",
    "CNN_OUTPUT_WIDTH, CNN_OUTPUT_CHANNELS = calculate_cnn_output_width(TARGET_IMG_HEIGHT, TARGET_IMG_WIDTH)\n",
    "# Kiểm tra xem width đã đủ lớn chưa\n",
    "if CNN_OUTPUT_WIDTH < 93: # So sánh với max label length\n",
    "     print(f\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "     print(f\"CẢNH BÁO: CNN_OUTPUT_WIDTH ({CNN_OUTPUT_WIDTH}) vẫn nhỏ hơn max label length (93).\")\n",
    "     print(f\"          CTC Loss có thể vẫn lỗi với các nhãn dài.\")\n",
    "     print(f\"          Cân nhắc tăng TARGET_IMG_WIDTH hơn nữa hoặc dùng CNN khác.\")\n",
    "     print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
    "else:\n",
    "     print(f\"Đã tính toán xong: CNN_OUTPUT_WIDTH = {CNN_OUTPUT_WIDTH} (>= 93), CNN_OUTPUT_CHANNELS = {CNN_OUTPUT_CHANNELS}\")\n",
    "\n",
    "\n",
    "# CẬP NHẬT TÊN KIẾN TRÚC ĐỂ LƯU CHECKPOINT\n",
    "EXPECTED_ARCHITECTURE = \"EfficientNetB0_Truncated_Early_CRNN\" # Tên mới hơn\n",
    "print(f\"Kiến trúc dự kiến cho checkpoint: {EXPECTED_ARCHITECTURE}\")"
   ],
   "id": "4109bcd47a73d1d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu tính toán CNN_OUTPUT_WIDTH và CNN_OUTPUT_CHANNELS cho CNN bị cắt bớt SỚM HƠN...\n",
      "Xây dựng kiến trúc CNN bị cắt bớt SỚM HƠN (ví dụ: EffNetB0 features[:3])...\n",
      "Xây dựng CNN bị cắt bớt thành công.\n",
      "Tạo dummy input shape: torch.Size([1, 3, 32, 384])\n",
      "Đang chạy dummy input qua CNN bị cắt bớt...\n",
      "Chạy dummy input thành công.\n",
      "--- Tính toán Output CNN (Truncated[:3] EfficientNet-B0) ---\n",
      "Input H=32, W=384\n",
      "Output shape after TRUNCATED[:3] features: [N, C, H, W] = torch.Size([1, 24, 8, 96])\n",
      "===> Số kênh output của CNN (C_out): 24\n",
      "===> Chiều rộng output của CNN (W_out / SeqLen for RNN): 96\n",
      "---------------------------------------------------------\n",
      "\n",
      "Đã tính toán xong: CNN_OUTPUT_WIDTH = 96 (>= 93), CNN_OUTPUT_CHANNELS = 24\n",
      "Kiến trúc dự kiến cho checkpoint: EfficientNetB0_Truncated_Early_CRNN\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:09:16.885316Z",
     "start_time": "2025-04-06T17:09:16.869225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI: Transforms cho ảnh HTR sử dụng EfficientNet ===\n",
    "# EfficientNet mong đợi ảnh 3 kênh và chuẩn hóa theo ImageNet\n",
    "\n",
    "htr_transform = transforms.Compose([\n",
    "    # Ảnh đã được resize và grayscale trong bước tiền xử lý trước đó\n",
    "    # và được load bằng PIL trong Dataset (nên là mode 'L')\n",
    "\n",
    "    # Chuyển PIL Image (mode 'L', H, W) [0-255] thành Tensor (1, H, W) [0, 1]\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # Lặp lại kênh đơn thành 3 kênh để phù hợp EfficientNet input (3, H, W)\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "\n",
    "    # Chuẩn hóa ImageNet cho 3 kênh\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"\\nĐã định nghĩa htr_transform cho EfficientNet.\")"
   ],
   "id": "7e4a611ce06c35fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đã định nghĩa htr_transform cho EfficientNet.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:09:19.995247Z",
     "start_time": "2025-04-06T17:09:19.978701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI NHẸ: Class Dataset (Thêm xử lý lỗi và trả về None) ===\n",
    "class CustomDatasetHTR(Dataset):\n",
    "    def __init__(self, image_paths, encoded_labels, transform=None):\n",
    "        # Đảm bảo số lượng paths và labels khớp nhau\n",
    "        if len(image_paths) != len(encoded_labels):\n",
    "            raise ValueError(f\"Số lượng image_paths ({len(image_paths)}) không khớp với encoded_labels ({len(encoded_labels)})!\")\n",
    "        self.image_paths = image_paths\n",
    "        self.encoded_labels = encoded_labels # List các list số nguyên\n",
    "        self.transform = transform\n",
    "        print(f\"Khởi tạo CustomDatasetHTR với {len(self.image_paths)} mẫu.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Lấy path và label gốc (list số nguyên)\n",
    "        img_path = self.image_paths[idx]\n",
    "        label_list = self.encoded_labels[idx]\n",
    "\n",
    "        # Chuyển đổi label thành tensor và kiểm tra rỗng sớm\n",
    "        try:\n",
    "            encoded_label_tensor = torch.tensor(label_list, dtype=torch.long)\n",
    "            if len(encoded_label_tensor) == 0:\n",
    "                 # Nhãn rỗng sau mã hóa, bỏ qua sample này\n",
    "                 # print(f\"Debug: Sample {idx} ({os.path.basename(img_path)}) has empty label list. Returning None.\")\n",
    "                 return None # collate_fn sẽ lọc bỏ\n",
    "        except Exception as e:\n",
    "             print(f\"Lỗi khi chuyển label list thành tensor cho sample {idx} ({os.path.basename(img_path)}): {e}\")\n",
    "             print(f\"Label list: {label_list}\")\n",
    "             return None # collate_fn sẽ lọc bỏ\n",
    "\n",
    "        # Xử lý ảnh\n",
    "        try:\n",
    "            # Mở ảnh bằng Pillow (chế độ mặc định)\n",
    "            image = Image.open(img_path)\n",
    "\n",
    "            # Đảm bảo ảnh là Grayscale ('L') trước khi áp dụng transform\n",
    "            if image.mode != 'L':\n",
    "                 # print(f\"Debug: Converting image {os.path.basename(img_path)} from mode {image.mode} to 'L'.\")\n",
    "                 image = image.convert('L')\n",
    "\n",
    "            # Áp dụng transform (bao gồm ToTensor, repeat channels, Normalize)\n",
    "            if self.transform:\n",
    "                image_tensor = self.transform(image)\n",
    "            else:\n",
    "                 # Nếu không có transform, cần tự chuyển sang Tensor và xử lý kênh\n",
    "                 # Nên luôn có transform cho model PyTorch\n",
    "                 image_tensor = transforms.ToTensor()(image) # Chỉ chuyển thành Tensor (1, H, W)\n",
    "                 # Cần xử lý kênh nếu không có transform lặp kênh\n",
    "                 if image_tensor.shape[0] == 1:\n",
    "                      image_tensor = image_tensor.repeat(3, 1, 1) # Lặp kênh thủ công\n",
    "\n",
    "            # Trả về ảnh tensor và label tensor\n",
    "            return image_tensor, encoded_label_tensor\n",
    "\n",
    "        except FileNotFoundError:\n",
    "             print(f\"Lỗi: Không tìm thấy file ảnh tại {img_path} cho sample {idx}.\")\n",
    "             return None # collate_fn sẽ lọc bỏ\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi tải hoặc transform ảnh {img_path} cho sample {idx}: {e}\")\n",
    "            import traceback\n",
    "            # traceback.print_exc() # Bỏ comment để xem chi tiết lỗi nếu cần\n",
    "            return None # collate_fn sẽ lọc bỏ"
   ],
   "id": "b7588d6c251dbf18",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4ad53d2cdc5409cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:09:23.617038Z",
     "start_time": "2025-04-06T17:09:23.609036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI: Hàm collate_fn với CNN_OUTPUT_WIDTH đã tính toán và lọc None ===\n",
    "\n",
    "def collate_fn_htr(batch):\n",
    "    # Lọc bỏ các sample bị lỗi (None) trả về từ __getitem__\n",
    "    # batch là list các tuple (image_tensor, label_tensor) hoặc None\n",
    "    original_batch_size = len(batch)\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    filtered_batch_size = len(batch)\n",
    "\n",
    "    # if original_batch_size != filtered_batch_size:\n",
    "    #      print(f\"Debug collate_fn: Filtered {original_batch_size - filtered_batch_size} None items from batch.\")\n",
    "\n",
    "    if not batch:\n",
    "        # print(\"Warning: Collate function received an empty batch after filtering None items.\")\n",
    "        return None, None, None, None # Trả về None nếu cả batch bị lỗi\n",
    "\n",
    "    try:\n",
    "        # Tách ảnh và nhãn từ batch đã lọc\n",
    "        images, labels = zip(*batch) # images là tuple các tensor ảnh, labels là tuple các tensor nhãn\n",
    "\n",
    "        # Xếp chồng ảnh thành batch tensor (N, C, H, W) - Bây giờ C sẽ là 3\n",
    "        images = torch.stack(images, 0)\n",
    "\n",
    "        # Pad labels (labels đã là tensor từ __getitem__)\n",
    "        # Tính độ dài trước khi pad\n",
    "        label_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)\n",
    "\n",
    "        # Lấy BLANK_TOKEN index từ char_to_int map (đảm bảo char_to_int đã tồn tại)\n",
    "        if 'char_to_int' not in globals() or 'BLANK_TOKEN' not in globals():\n",
    "             raise NameError(\"char_to_int hoặc BLANK_TOKEN chưa được định nghĩa!\")\n",
    "        blank_token_idx = char_to_int.get(BLANK_TOKEN, 0) # Mặc định là 0 nếu không tìm thấy\n",
    "\n",
    "        # Thực hiện padding\n",
    "        padded_labels = pad_sequence(labels, batch_first=True, padding_value=blank_token_idx)\n",
    "\n",
    "        # Tính toán input lengths cho CTCLoss (chiều dài sequence từ CNN output)\n",
    "        # Sử dụng giá trị CNN_OUTPUT_WIDTH đã tính toán tự động\n",
    "        if 'CNN_OUTPUT_WIDTH' not in globals():\n",
    "             raise NameError(\"Biến toàn cục CNN_OUTPUT_WIDTH chưa được tính toán!\")\n",
    "        # Kích thước batch hiện tại có thể nhỏ hơn BATCH_SIZE do lọc None\n",
    "        current_batch_size = images.size(0)\n",
    "        input_lengths = torch.full(size=(current_batch_size,), fill_value=CNN_OUTPUT_WIDTH, dtype=torch.long)\n",
    "\n",
    "        # Kiểm tra độ dài hợp lệ (đề phòng lỗi CTC)\n",
    "        if torch.any(label_lengths <= 0):\n",
    "            print(f\"Warning collate_fn: Batch contains labels with length <= 0.\")\n",
    "            # print(f\"Label lengths in batch: {label_lengths}\")\n",
    "            # Có thể cần lọc lại batch ở đây nếu CTC không xử lý được\n",
    "            # Hoặc đảm bảo Dataset không trả về nhãn rỗng\n",
    "\n",
    "        return images, padded_labels, input_lengths, label_lengths\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(f\"Lỗi nghiêm trọng trong collate_fn_htr: {e}\")\n",
    "        print(f\"Kiểm tra lại dữ liệu đầu vào và logic padding.\")\n",
    "        # print(f\"Batch size after filtering: {len(batch)}\")\n",
    "        # In thông tin các phần tử trong batch để debug\n",
    "        # for i, item in enumerate(batch):\n",
    "        #      if item is not None:\n",
    "        #           print(f\" Batch item {i}: Image shape {item[0].shape}, Label shape {item[1].shape}\")\n",
    "        #      else:\n",
    "        #           print(f\" Batch item {i}: None\")\n",
    "        print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Trả về None để bỏ qua batch này trong vòng lặp huấn luyện\n",
    "        return None, None, None, None\n",
    "\n",
    "# Chỉ in khi cell được chạy\n",
    "if 'CNN_OUTPUT_WIDTH' in globals():\n",
    "    print(f\"\\nĐã định nghĩa collate_fn_htr với CNN_OUTPUT_WIDTH = {CNN_OUTPUT_WIDTH}\")\n",
    "else:\n",
    "    print(\"\\nĐã định nghĩa collate_fn_htr, nhưng CNN_OUTPUT_WIDTH chưa được tính (chạy cell tính toán trước).\")"
   ],
   "id": "462281b074d8cae3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đã định nghĩa collate_fn_htr với CNN_OUTPUT_WIDTH = 96\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:09:29.087811Z",
     "start_time": "2025-04-06T17:09:29.022797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Thử load dữ liệu đã mã hóa từ file JSON - tùy chọn) ===\n",
    "# Cell này chủ yếu để xác nhận file đã lưu đúng, dữ liệu chính đã được mã hóa và lọc ở các cell trên.\n",
    "\n",
    "print(\"\\nKiểm tra và thử tải lại dữ liệu đã mã hóa từ file JSON (để xác nhận)...\")\n",
    "loaded_encoded_data_check = False # Flag kiểm tra\n",
    "if os.path.exists(encoded_train_path) and \\\n",
    "   os.path.exists(encoded_test_path) and \\\n",
    "   os.path.exists(charmap_path):\n",
    "    try:\n",
    "        # Chỉ tải để kiểm tra, không ghi đè biến hiện tại trừ khi có lý do\n",
    "        with open(encoded_train_path, 'r', encoding='utf-8') as f_train:\n",
    "            _ = json.load(f_train) # Tải vào biến tạm\n",
    "        with open(encoded_test_path, 'r', encoding='utf-8') as f_test:\n",
    "            _ = json.load(f_test)\n",
    "        with open(charmap_path, 'r', encoding='utf-8') as f_map:\n",
    "            _ = json.load(f_map)\n",
    "\n",
    "        print(f\"Kiểm tra tải file JSON thành công: {encoded_train_path}, {encoded_test_path}, {charmap_path}\")\n",
    "        loaded_encoded_data_check = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi kiểm tra tải file JSON đã mã hóa: {e}. Tiếp tục với dữ liệu trong bộ nhớ.\")\n",
    "else:\n",
    "    print(\"Không tìm thấy một hoặc nhiều file JSON đã mã hóa/charmap để kiểm tra.\")"
   ],
   "id": "e094d5e9d9fe78b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kiểm tra và thử tải lại dữ liệu đã mã hóa từ file JSON (để xác nhận)...\n",
      "Kiểm tra tải file JSON thành công: E:\\HANDS-VNOnDB\\encoded_train_word_labels.json, E:\\HANDS-VNOnDB\\encoded_test_word_labels.json, E:\\HANDS-VNOnDB\\character_map.json\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:09:31.895891Z",
     "start_time": "2025-04-06T17:09:31.888401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Tạo Dataset) ===\n",
    "# Tạo Dataset và DataLoader mới với dữ liệu đã lọc và transform mới\n",
    "# Đảm bảo X_train_paths, y_train_encoded, X_test_paths, y_test_encoded là các phiên bản đã lọc\n",
    "\n",
    "# Kiểm tra lại dữ liệu trước khi tạo Dataset\n",
    "if not X_train_paths or not y_train_encoded:\n",
    "     print(\"Lỗi: Không có dữ liệu huấn luyện hợp lệ sau khi lọc. Không thể tạo Dataset.\")\n",
    "     # exit()\n",
    "elif not X_test_paths or not y_test_encoded:\n",
    "     print(\"Cảnh báo: Không có dữ liệu kiểm tra hợp lệ sau khi lọc. Tập test sẽ rỗng.\")\n",
    "     # Tạo test_dataset rỗng hoặc xử lý phù hợp\n",
    "     test_dataset_htr = None # Hoặc dataset rỗng\n",
    "else:\n",
    "     print(f\"\\nSẵn sàng tạo Dataset với {len(X_train_paths)} mẫu train và {len(X_test_paths)} mẫu test.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    train_dataset_htr = CustomDatasetHTR(X_train_paths, y_train_encoded, transform=htr_transform)\n",
    "    print(f\"Đã tạo train_dataset_htr.\")\n",
    "\n",
    "    # Chỉ tạo test_dataset nếu có dữ liệu test\n",
    "    if X_test_paths and y_test_encoded:\n",
    "         test_dataset_htr = CustomDatasetHTR(X_test_paths, y_test_encoded, transform=htr_transform)\n",
    "         print(f\"Đã tạo test_dataset_htr.\")\n",
    "    else:\n",
    "         print(\"Không có dữ liệu test hợp lệ, test_dataset_htr sẽ là None.\")\n",
    "         test_dataset_htr = None\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"\\nLỗi khi khởi tạo CustomDatasetHTR: {e}\")\n",
    "     print(\"Kiểm tra lại dữ liệu đầu vào (paths, labels) và class Dataset.\")\n",
    "     # exit()"
   ],
   "id": "84a876bc0e4080a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sẵn sàng tạo Dataset với 26579 mẫu train và 6645 mẫu test.\n",
      "Khởi tạo CustomDatasetHTR với 26579 mẫu.\n",
      "Đã tạo train_dataset_htr.\n",
      "Khởi tạo CustomDatasetHTR với 6645 mẫu.\n",
      "Đã tạo test_dataset_htr.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:09:44.106773Z",
     "start_time": "2025-04-06T17:09:44.098771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Tạo DataLoader) ===\n",
    "# Điều chỉnh batch_size tùy theo bộ nhớ GPU/CPU\n",
    "BATCH_SIZE = 32 # Giữ nguyên hoặc giảm nếu gặp lỗi CUDA out of memory\n",
    "NUM_WORKERS = 0 # Đặt là 0 để dễ debug, tăng lên (ví dụ 2 hoặc 4) để tăng tốc độ nếu không có lỗi\n",
    "\n",
    "print(f\"\\nĐang tạo DataLoaders với batch_size={BATCH_SIZE}, num_workers={NUM_WORKERS}...\")\n",
    "\n",
    "# Tạo train_loader\n",
    "if 'train_dataset_htr' in globals() and train_dataset_htr is not None and len(train_dataset_htr) > 0:\n",
    "    train_loader_htr = DataLoader(\n",
    "        train_dataset_htr,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn_htr, # Sử dụng collate function đã định nghĩa\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False # Pin memory nếu dùng CUDA\n",
    "    )\n",
    "    print(f\"Đã tạo train_loader_htr với {len(train_loader_htr)} batches.\")\n",
    "else:\n",
    "     print(\"Lỗi: train_dataset_htr không hợp lệ hoặc rỗng. Không thể tạo train_loader.\")\n",
    "     train_loader_htr = None # Đặt là None để xử lý lỗi sau\n",
    "\n",
    "\n",
    "# Tạo test_loader (chỉ nếu test_dataset hợp lệ)\n",
    "if 'test_dataset_htr' in globals() and test_dataset_htr is not None and len(test_dataset_htr) > 0:\n",
    "    test_loader_htr = DataLoader(\n",
    "        test_dataset_htr,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False, # Không cần shuffle test set\n",
    "        collate_fn=collate_fn_htr,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    print(f\"Đã tạo test_loader_htr với {len(test_loader_htr)} batches.\")\n",
    "else:\n",
    "     print(\"test_dataset_htr không hợp lệ hoặc rỗng. test_loader_htr sẽ là None.\")\n",
    "     test_loader_htr = None\n",
    "\n",
    "\n"
   ],
   "id": "5e7fd7cfda4d7009",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đang tạo DataLoaders với batch_size=32, num_workers=0...\n",
      "Đã tạo train_loader_htr với 831 batches.\n",
      "Đã tạo test_loader_htr với 208 batches.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:09:53.560622Z",
     "start_time": "2025-04-06T17:09:53.541677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI: Định nghĩa mô hình CRNN với EfficientNet-B0 BỊ CẮT BỚT SỚM HƠN ===\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes, rnn_hidden_size=256, rnn_num_layers=2, dropout=0.5):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        # --- Phần CNN: Sử dụng EfficientNet-B0 Pre-trained BỊ CẮT BỚT SỚM HƠN ---\n",
    "        weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "        effnet_full = models.efficientnet_b0(weights=weights)\n",
    "\n",
    "        # Xây dựng CNN bị cắt bớt SỚM HƠN (phải giống hệt cell tính toán width)\n",
    "        # Ví dụ: lấy 3 block đầu tiên (index 0 đến 2) -> features[:3]\n",
    "        self.cnn = nn.Sequential(*list(effnet_full.features[:3]))\n",
    "        print(\"Đã xây dựng CNN bị cắt bớt SỚM HƠN từ EfficientNet-B0 pre-trained.\")\n",
    "\n",
    "        # Lấy số kênh output từ CNN đã tính toán trước đó\n",
    "        if 'CNN_OUTPUT_CHANNELS' not in globals():\n",
    "             raise NameError(\"Biến toàn cục CNN_OUTPUT_CHANNELS chưa được tính toán!\")\n",
    "        self.cnn_output_channels = CNN_OUTPUT_CHANNELS # Sẽ là output của block 2 (40)\n",
    "\n",
    "        # --- Adaptive Pooling để đảm bảo H_out = 1 ---\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, None))\n",
    "\n",
    "        # --- Phần RNN ---\n",
    "        print(f\"Input size cho LSTM sẽ là: {self.cnn_output_channels}\") # Kênh ít hơn\n",
    "        self.rnn = nn.LSTM(self.cnn_output_channels, rnn_hidden_size, rnn_num_layers,\n",
    "                           bidirectional=True, batch_first=False, dropout=dropout if rnn_num_layers > 1 else 0)\n",
    "\n",
    "        self.dropout_rnn_out = nn.Dropout(dropout)\n",
    "\n",
    "        # --- Phần Fully Connected ---\n",
    "        self.fc = nn.Linear(rnn_hidden_size * 2, num_classes)\n",
    "\n",
    "        print(\"--- Khởi tạo CRNN với EfficientNet-B0 BỊ CẮT BỚT SỚM HƠN ---\")\n",
    "        print(f\"CNN Backbone: Truncated EfficientNet-B0 Features (ví dụ: [:3])\") # Cập nhật mô tả\n",
    "        print(f\"CNN Output Channels (to RNN): {self.cnn_output_channels}\")\n",
    "        print(f\"CNN Output Width (SeqLen for RNN - đã tính): {CNN_OUTPUT_WIDTH}\") # In ra để kiểm tra\n",
    "        # ... (Các thông số RNN/Dropout giữ nguyên) ...\n",
    "        print(f\"RNN Hidden Size: {rnn_hidden_size}\")\n",
    "        print(f\"RNN Num Layers: {rnn_num_layers}\")\n",
    "        print(f\"Output Classes (incl. blank): {num_classes}\")\n",
    "        print(\"------------------------------------------------------\")\n",
    "\n",
    "        del effnet_full\n",
    "        gc.collect()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ... (Logic forward giữ nguyên như trước) ...\n",
    "        features = self.cnn(x)\n",
    "        features = self.adaptive_pool(features)\n",
    "        features = features.squeeze(2)\n",
    "        features = features.permute(2, 0, 1)\n",
    "        self.rnn.flatten_parameters()\n",
    "        rnn_output, _ = self.rnn(features)\n",
    "        rnn_output = self.dropout_rnn_out(rnn_output)\n",
    "        output = self.fc(rnn_output)\n",
    "        return output"
   ],
   "id": "94f1803d48c1ca23",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T17:09:56.420929Z",
     "start_time": "2025-04-06T17:09:56.169758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI: Khởi tạo model CRNN mới, kiểm tra device và forward ===\n",
    "# Kiểm tra device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nSử dụng device: {device}\")\n",
    "\n",
    "# Khởi tạo model CRNN với backbone EfficientNet\n",
    "# Đảm bảo num_classes_htr đã được tính toán chính xác\n",
    "if 'num_classes_htr' not in globals():\n",
    "     raise NameError(\"Biến num_classes_htr chưa được định nghĩa!\")\n",
    "\n",
    "print(f\"Khởi tạo model CRNN (EfficientNet) với {num_classes_htr} lớp đầu ra.\")\n",
    "model_htr = CRNN(num_classes=num_classes_htr) # Các tham số RNN/dropout dùng default\n",
    "model_htr = model_htr.to(device)\n",
    "print(\"Khởi tạo mô hình CRNN (EfficientNet Backbone) thành công.\")\n",
    "\n"
   ],
   "id": "10cefce4ac86f0a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sử dụng device: cpu\n",
      "Khởi tạo model CRNN (EfficientNet) với 144 lớp đầu ra.\n",
      "Đã xây dựng CNN bị cắt bớt SỚM HƠN từ EfficientNet-B0 pre-trained.\n",
      "Input size cho LSTM sẽ là: 24\n",
      "--- Khởi tạo CRNN với EfficientNet-B0 BỊ CẮT BỚT SỚM HƠN ---\n",
      "CNN Backbone: Truncated EfficientNet-B0 Features (ví dụ: [:3])\n",
      "CNN Output Channels (to RNN): 24\n",
      "CNN Output Width (SeqLen for RNN - đã tính): 96\n",
      "RNN Hidden Size: 256\n",
      "RNN Num Layers: 2\n",
      "Output Classes (incl. blank): 144\n",
      "------------------------------------------------------\n",
      "Khởi tạo mô hình CRNN (EfficientNet Backbone) thành công.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T03:02:02.923862Z",
     "start_time": "2025-04-07T03:02:02.391744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI: Loss, Optimizer, Checkpoint handling (Cập nhật tên checkpoint và architecture) ===\n",
    "\n",
    "# ... (Phần định nghĩa criterion, optimizer giữ nguyên) ...\n",
    "if 'char_to_int' not in globals() or 'BLANK_TOKEN' not in globals(): #... (Kiểm tra blank_idx) ...\n",
    "    raise NameError(\"char_to_int hoặc BLANK_TOKEN chưa được định nghĩa!\")\n",
    "blank_idx = char_to_int.get(BLANK_TOKEN)\n",
    "if blank_idx is None: raise ValueError(f\"'{BLANK_TOKEN}' không tìm thấy trong char_to_int!\")\n",
    "criterion_htr = nn.CTCLoss(blank=blank_idx, reduction='mean', zero_infinity=True)\n",
    "print(f\"\\nĐã khởi tạo CTCLoss với blank index = {blank_idx}\")\n",
    "\n",
    "INITIAL_LR = 5e-5\n",
    "optimizer_htr = optim.AdamW(model_htr.parameters(), lr=INITIAL_LR, weight_decay=1e-1)\n",
    "print(f\"Đã khởi tạo Optimizer AdamW với LR = {INITIAL_LR}\")\n",
    "\n",
    "\n",
    "# --- CẬP NHẬT CHECKPOINT PATH VÀ ARCHITECTURE NAME ---\n",
    "CHECKPOINT_DIR = r\"G:\\Compvision Final\\pythonProject\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "# Đổi tên file để phân biệt với kiến trúc TRUNCATED SỚM\n",
    "CHECKPOINT_FILENAME = \"checkpoint_htr_word_effnet_trunc_early.pth\" # Tên file mới hơn\n",
    "CHECKPOINT_PATH_HTR = os.path.join(CHECKPOINT_DIR, CHECKPOINT_FILENAME)\n",
    "# Sử dụng EXPECTED_ARCHITECTURE đã cập nhật ở cell tính toán width\n",
    "print(f\"Kiến trúc dự kiến: {EXPECTED_ARCHITECTURE}\")\n",
    "print(f\"Đường dẫn checkpoint mới: {CHECKPOINT_PATH_HTR}\")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Training parameters\n",
    "START_EPOCH_HTR = 0\n",
    "NUM_EPOCHS = 60 # Đặt số epoch bạn muốn\n",
    "train_losses = []\n",
    "val_losses = [] # Vẫn giữ nếu bạn muốn thêm lại validation sau này\n",
    "\n",
    "# --- Load Checkpoint nếu có VÀ KIẾN TRÚC PHÙ HỢP (DÙNG TÊN MỚI NHẤT) ---\n",
    "if os.path.exists(CHECKPOINT_PATH_HTR):\n",
    "    print(f\"\\nTìm thấy checkpoint tại: {CHECKPOINT_PATH_HTR}\")\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH_HTR, map_location=device)\n",
    "        print(\"Tải file checkpoint thành công.\")\n",
    "        # ... (Phần kiểm tra architecture và load state dict giữ nguyên logic như cell trước) ...\n",
    "        loaded_architecture = checkpoint.get('architecture')\n",
    "        if loaded_architecture != EXPECTED_ARCHITECTURE:\n",
    "             print(f\"\\nCẢNH BÁO: Checkpoint '{loaded_architecture}' != Hiện tại '{EXPECTED_ARCHITECTURE}'. Bắt đầu lại.\")\n",
    "             START_EPOCH_HTR = 0\n",
    "        else:\n",
    "             print(f\"Kiến trúc checkpoint khớp. Đang tải trạng thái...\")\n",
    "             # ... (load state dicts, epoch, losses, kiểm tra CNN width) ...\n",
    "             try:\n",
    "                 model_htr.load_state_dict(checkpoint['model_state_dict'])\n",
    "                 optimizer_htr.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                 START_EPOCH_HTR = checkpoint.get('epoch', -1) + 1\n",
    "                 train_losses = checkpoint.get('train_losses', [])\n",
    "                 loaded_cnn_output_width = checkpoint.get('cnn_output_width', -1)\n",
    "                 if loaded_cnn_output_width != -1 and loaded_cnn_output_width != CNN_OUTPUT_WIDTH:\n",
    "                      print(f\"\\nCẢNH BÁO: Width checkpoint ({loaded_cnn_output_width}) != hiện tại ({CNN_OUTPUT_WIDTH})!\")\n",
    "                 print(f\"\\n===> Đã tải checkpoint. Tiếp tục huấn luyện từ epoch {START_EPOCH_HTR}\")\n",
    "             except (KeyError, RuntimeError) as e_load:\n",
    "                 print(f\"\\nLỗi khi tải state_dict: {e_load}. Bắt đầu lại.\")\n",
    "                 START_EPOCH_HTR = 0; train_losses = []\n",
    "                 # Khởi tạo lại nếu cần\n",
    "                 if 'model_htr' not in locals(): model_htr = CRNN(num_classes=num_classes_htr).to(device)\n",
    "                 if 'optimizer_htr' not in locals(): optimizer_htr = optim.AdamW(model_htr.parameters(), lr=INITIAL_LR, weight_decay=5e-4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nLỗi không xác định khi tải checkpoint: {e}. Bắt đầu lại.\")\n",
    "        START_EPOCH_HTR = 0; train_losses = []\n",
    "        # Khởi tạo lại nếu cần\n",
    "        if 'model_htr' not in locals(): model_htr = CRNN(num_classes=num_classes_htr).to(device)\n",
    "        if 'optimizer_htr' not in locals(): optimizer_htr = optim.AdamW(model_htr.parameters(), lr=INITIAL_LR, weight_decay=5e-4)\n",
    "else:\n",
    "    print(f\"\\nKhông tìm thấy checkpoint tại {CHECKPOINT_PATH_HTR}. Bắt đầu huấn luyện từ đầu (epoch 1).\")\n",
    "\n",
    "# Dọn dẹp\n",
    "if 'checkpoint' in locals(): del checkpoint\n",
    "gc.collect()\n",
    "if torch.cuda.is_available(): torch.cuda.empty_cache()"
   ],
   "id": "883e17220bda455c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đã khởi tạo CTCLoss với blank index = 0\n",
      "Đã khởi tạo Optimizer AdamW với LR = 5e-05\n",
      "Kiến trúc dự kiến: EfficientNetB0_Truncated_Early_CRNN\n",
      "Đường dẫn checkpoint mới: G:\\Compvision Final\\pythonProject\\checkpoint_htr_word_effnet_trunc_early.pth\n",
      "\n",
      "Tìm thấy checkpoint tại: G:\\Compvision Final\\pythonProject\\checkpoint_htr_word_effnet_trunc_early.pth\n",
      "Tải file checkpoint thành công.\n",
      "Kiến trúc checkpoint khớp. Đang tải trạng thái...\n",
      "\n",
      "===> Đã tải checkpoint. Tiếp tục huấn luyện từ epoch 50\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T03:02:07.347711Z",
     "start_time": "2025-04-07T03:02:07.328710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Hàm giải mã Greedy) ===\n",
    "def decode_batch(outputs, int_to_char_map, blank_token_idx):\n",
    "    \"\"\"\n",
    "    Giải mã output của model (sau FC layer) thành chuỗi text sử dụng Greedy search.\n",
    "    Args:\n",
    "        outputs (torch.Tensor): Tensor output từ model. Shape: (SeqLen, Batch, NumClasses)\n",
    "        int_to_char_map (dict): Map từ index sang ký tự.\n",
    "        blank_token_idx (int): Index của blank token.\n",
    "    Returns:\n",
    "        list[str]: Danh sách các chuỗi text đã giải mã cho batch.\n",
    "    \"\"\"\n",
    "    # Lấy argmax theo chiều class (dim=2) -> Shape: (SeqLen, Batch)\n",
    "    # Chuyển sang CPU để xử lý numpy/list dễ hơn\n",
    "    preds = torch.argmax(outputs.detach().cpu(), dim=2)\n",
    "    # Chuyển vị thành (Batch, SeqLen)\n",
    "    preds = preds.permute(1, 0).numpy()\n",
    "\n",
    "    decoded_texts = []\n",
    "    for pred_seq in preds:\n",
    "        text = []\n",
    "        last_char_idx = -1 # Dùng index thay vì ký tự để so sánh\n",
    "        for idx in pred_seq:\n",
    "            # Bỏ qua blank token và các ký tự lặp lại liên tiếp\n",
    "            if idx != blank_token_idx and idx != last_char_idx:\n",
    "                char = int_to_char_map.get(idx)\n",
    "                if char: # Chỉ thêm nếu ký tự tồn tại trong map\n",
    "                    text.append(char)\n",
    "            last_char_idx = idx # Luôn cập nhật last_char_idx\n",
    "        decoded_texts.append(\"\".join(text))\n",
    "    return decoded_texts"
   ],
   "id": "e2d775cc61feb45e",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T03:02:09.496786Z",
     "start_time": "2025-04-07T03:02:09.479165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer_htr, step_size=3, gamma=0.7)"
   ],
   "id": "c404bbe1cd0ea333",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T03:02:31.439755900Z",
     "start_time": "2025-04-07T03:02:11.312237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI: Vòng lặp Huấn luyện (BỎ HOÀN TOÀN VALIDATION) ===\n",
    "\n",
    "# Kiểm tra DataLoader trước khi bắt đầu\n",
    "if not train_loader_htr:\n",
    "     print(\"\\nLỗi: train_loader_htr không hợp lệ. Không thể bắt đầu huấn luyện.\")\n",
    "     exit() # Nên dừng ở đây nếu không có dữ liệu huấn luyện\n",
    "\n",
    "print(f\"\\nBắt đầu huấn luyện từ epoch {START_EPOCH_HTR + 1} đến {NUM_EPOCHS} (KHÔNG Validation)\")\n",
    "\n",
    "# Reset lại list loss nếu bắt đầu từ đầu\n",
    "if START_EPOCH_HTR == 0:\n",
    "    train_losses = []\n",
    "    # val_losses = [] # Không cần val_losses nữa\n",
    "\n",
    "\n",
    "for epoch in range(START_EPOCH_HTR, NUM_EPOCHS):\n",
    "    epoch_num = epoch + 1\n",
    "    print(f\"\\n===== Epoch {epoch_num}/{NUM_EPOCHS} =====\")\n",
    "\n",
    "    # --- Training Phase ---\n",
    "    model_htr.train() # Đặt model ở chế độ training\n",
    "    running_loss = 0.0\n",
    "    num_train_samples_processed = 0\n",
    "    train_batches_processed = 0\n",
    "\n",
    "    train_progress_bar = tqdm(train_loader_htr, desc=f\"Epoch {epoch_num} [Train]\", unit=\"batch\")\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_progress_bar):\n",
    "        # Kiểm tra xem collate_fn có trả về None không\n",
    "        if batch_data is None or batch_data[0] is None:\n",
    "            continue # Bỏ qua batch không hợp lệ\n",
    "\n",
    "        images, padded_labels, input_lengths, label_lengths = batch_data\n",
    "        current_batch_size = images.size(0)\n",
    "\n",
    "        # Chuyển dữ liệu lên device\n",
    "        images = images.to(device)\n",
    "        padded_labels = padded_labels.to(device)\n",
    "        input_lengths = input_lengths.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "\n",
    "        # --- Forward pass ---\n",
    "        optimizer_htr.zero_grad()\n",
    "        outputs = model_htr(images) # output shape: (SeqLen, Batch, NumClasses)\n",
    "\n",
    "        # --- Calculate CTC Loss ---\n",
    "        log_probs = nn.functional.log_softmax(outputs, dim=2)\n",
    "\n",
    "        # Điều chỉnh input lengths nếu cần (dù không nên xảy ra nếu CNN_OUTPUT_WIDTH đúng)\n",
    "        valid_input_lengths = torch.clamp(input_lengths, max=log_probs.shape[0])\n",
    "        # Đảm bảo label_lengths > 0\n",
    "        valid_label_lengths = torch.clamp(label_lengths, min=1)\n",
    "\n",
    "        # Tính loss\n",
    "        try:\n",
    "            loss = criterion_htr(log_probs, padded_labels, valid_input_lengths, valid_label_lengths)\n",
    "\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"\\nWarning: NaN/Inf loss in train batch {batch_idx}. Skipping backward pass.\")\n",
    "                continue\n",
    "\n",
    "            # --- Backward pass and Optimization ---\n",
    "            loss.backward()\n",
    "            optimizer_htr.step()\n",
    "\n",
    "            # Tích lũy loss\n",
    "            running_loss += loss.item() * current_batch_size\n",
    "            num_train_samples_processed += current_batch_size\n",
    "            train_batches_processed += 1\n",
    "\n",
    "            # Cập nhật thanh progress bar\n",
    "            train_progress_bar.set_postfix(loss=f\"{loss.item():.4f}\", lr=f\"{optimizer_htr.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "        except RuntimeError as rte:\n",
    "             if \"targets must be shorter than the T dimension\" in str(rte):\n",
    "                  # print(f\"\\nLỗi CTC trong train batch {batch_idx}: Target length > Input length. Skipping.\") # Có thể bật để debug\n",
    "                  # print(f\"  Input lengths (max {log_probs.shape[0]}): {valid_input_lengths.tolist()}\")\n",
    "                  # print(f\"  Target lengths: {valid_label_lengths.tolist()}\")\n",
    "                  continue\n",
    "             else:\n",
    "                  print(f\"\\nLỗi RuntimeError trong training step (batch {batch_idx}): {rte}\")\n",
    "                  traceback.print_exc()\n",
    "                  continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\nLỗi không xác định trong training step (batch {batch_idx}): {e}\")\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    # Tính loss trung bình cho epoch training\n",
    "    if num_train_samples_processed > 0:\n",
    "        avg_train_loss = running_loss / num_train_samples_processed\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch_num} [Train] Average Loss: {avg_train_loss:.4f} ({train_batches_processed} batches)\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch_num} [Train] No batches processed successfully.\")\n",
    "        train_losses.append(float('inf')) # Ghi nhận lỗi nếu không có batch nào thành công\n",
    "\n",
    "\n",
    "    # --- KHÔNG CÓ VALIDATION PHASE ---\n",
    "\n",
    "\n",
    "    # --- Adjust Learning Rate (Optional - Không dựa vào val_loss) ---\n",
    "    # Ví dụ: Giảm LR sau một số epoch cố định\n",
    "    if 'scheduler' in locals() and isinstance(scheduler, optim.lr_scheduler.StepLR):\n",
    "         scheduler.step()\n",
    "         print(f\"Current LR: {optimizer_htr.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "\n",
    "    # --- Lưu Checkpoint SAU MỖI EPOCH ---\n",
    "    # Chỉ lưu checkpoint cuối cùng của epoch đó\n",
    "    checkpoint_data = {\n",
    "        'epoch': epoch,\n",
    "        'architecture': EXPECTED_ARCHITECTURE,\n",
    "        'model_state_dict': model_htr.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_htr.state_dict(),\n",
    "        'char_to_int': char_to_int,\n",
    "        'train_losses': train_losses,\n",
    "        # 'val_losses': [], # Không lưu val_losses\n",
    "        # 'best_val_loss': float('inf'), # Không lưu best_val_loss\n",
    "        'target_img_width': TARGET_IMG_WIDTH,\n",
    "        'target_img_height': TARGET_IMG_HEIGHT,\n",
    "        'cnn_output_width': CNN_OUTPUT_WIDTH\n",
    "    }\n",
    "    try:\n",
    "        torch.save(checkpoint_data, CHECKPOINT_PATH_HTR)\n",
    "        # Bỏ comment dòng dưới nếu muốn thấy log lưu mỗi epoch\n",
    "        # print(f\"Checkpoint saved after epoch {epoch_num} to {CHECKPOINT_PATH_HTR}\")\n",
    "    except Exception as e_save:\n",
    "         print(f\"Lỗi khi lưu checkpoint tại epoch {epoch_num}: {e_save}\")\n",
    "\n",
    "\n",
    "# --- Kết thúc vòng lặp huấn luyện ---\n",
    "print(\"\\n===== Hoàn thành huấn luyện (Không có validation)! =====\")\n",
    "\n",
    "# Vẽ đồ thị loss (chỉ có train loss)\n",
    "if train_losses:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # Lưu đồ thị nếu muốn\n",
    "    loss_plot_path = os.path.join(CHECKPOINT_DIR, f\"loss_plot_{EXPECTED_ARCHITECTURE}_train_only.png\")\n",
    "    try:\n",
    "        plt.savefig(loss_plot_path)\n",
    "        print(f\"Đã lưu đồ thị loss vào: {loss_plot_path}\")\n",
    "    except Exception as e_plot:\n",
    "        print(f\"Lỗi khi lưu đồ thị loss: {e_plot}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Không có dữ liệu train loss để vẽ đồ thị.\")"
   ],
   "id": "4509981b916d8df2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bắt đầu huấn luyện từ epoch 51 đến 60 (KHÔNG Validation)\n",
      "\n",
      "===== Epoch 51/60 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 [Train]:   3%|▎         | 28/831 [00:20<09:37,  1.39batch/s, loss=1.7167, lr=1.7e-07]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[55], line 28\u001B[0m\n\u001B[0;32m     24\u001B[0m train_batches_processed \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     26\u001B[0m train_progress_bar \u001B[38;5;241m=\u001B[39m tqdm(train_loader_htr, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch_num\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m [Train]\u001B[39m\u001B[38;5;124m\"\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, batch_data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_progress_bar):\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;66;03m# Kiểm tra xem collate_fn có trả về None không\u001B[39;00m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m batch_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m batch_data[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     31\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m \u001B[38;5;66;03m# Bỏ qua batch không hợp lệ\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 708\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    714\u001B[0m ):\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    762\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    763\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 764\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    766\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[28], line 35\u001B[0m, in \u001B[0;36mCustomDatasetHTR.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# Xử lý ảnh\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;66;03m# Mở ảnh bằng Pillow (chế độ mặc định)\u001B[39;00m\n\u001B[1;32m---> 35\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;66;03m# Đảm bảo ảnh là Grayscale ('L') trước khi áp dụng transform\u001B[39;00m\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m image\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     39\u001B[0m          \u001B[38;5;66;03m# print(f\"Debug: Converting image {os.path.basename(img_path)} from mode {image.mode} to 'L'.\")\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\PIL\\Image.py:3465\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3462\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(fp)\n\u001B[0;32m   3464\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3465\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3466\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3467\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T23:46:16.349416Z",
     "start_time": "2025-04-06T23:46:16.333867Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"DEBUG: Batch {batch_idx}, LogProbs SeqLen: {log_probs.shape[0]}, InputLengths Max: {valid_input_lengths.max().item()}, LabelLengths Max: {valid_label_lengths.max().item()}\")",
   "id": "13cc401cbd91c24a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Batch 830, LogProbs SeqLen: 96, InputLengths Max: 96, LabelLengths Max: 6\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T23:46:17.890903Z",
     "start_time": "2025-04-06T23:46:17.874902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Import jiwer để đánh giá) ===\n",
    "try:\n",
    "    import jiwer\n",
    "    print(\"jiwer library imported successfully.\")\n",
    "    # Định nghĩa transformation cơ bản cho jiwer (thường là lowercase và bỏ dấu câu)\n",
    "    jiwer_transform = jiwer.Compose([\n",
    "        jiwer.ToLowerCase(),\n",
    "        jiwer.RemoveMultipleSpaces(),\n",
    "        jiwer.RemovePunctuation(),\n",
    "        jiwer.Strip()\n",
    "    ])\n",
    "    print(\"Defined basic jiwer transformation.\")\n",
    "except ImportError:\n",
    "    print(\"Lỗi: Thư viện jiwer chưa được cài đặt.\")\n",
    "    print(\"Vui lòng cài đặt bằng lệnh: pip install jiwer\")\n",
    "    jiwer = None # Đặt là None để kiểm tra trước khi sử dụng\n",
    "    jiwer_transform = None"
   ],
   "id": "67e22dc3316458f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jiwer library imported successfully.\n",
      "Defined basic jiwer transformation.\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T23:46:20.199710Z",
     "start_time": "2025-04-06T23:46:20.185713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Hàm giải mã nhãn gốc từ dạng padded) ===\n",
    "def decode_padded_labels(padded_labels, label_lengths, int_to_char_map):\n",
    "    \"\"\"\n",
    "    Chuyển đổi batch label đã được pad và tensor độ dài tương ứng\n",
    "    thành một list các chuỗi text gốc.\n",
    "    Args:\n",
    "        padded_labels (torch.Tensor): Shape: (Batch, MaxLength). Nên ở trên CPU.\n",
    "        label_lengths (torch.Tensor): Shape: (Batch,). Nên ở trên CPU.\n",
    "        int_to_char_map (dict): Map từ index sang ký tự.\n",
    "    Returns:\n",
    "        list[str]: List các chuỗi text gốc đã được giải mã.\n",
    "    \"\"\"\n",
    "    ground_truth_texts = []\n",
    "    padded_labels_cpu = padded_labels.cpu()\n",
    "    label_lengths_cpu = label_lengths.cpu()\n",
    "    for i in range(padded_labels_cpu.size(0)):\n",
    "        actual_len = label_lengths_cpu[i].item()\n",
    "        if actual_len > 0:\n",
    "            label_indices = padded_labels_cpu[i][:actual_len].tolist()\n",
    "            try:\n",
    "                text = \"\".join([int_to_char_map.get(idx, '') for idx in label_indices])\n",
    "                ground_truth_texts.append(text)\n",
    "            except Exception as e:\n",
    "                print(f\"Error decoding GT indices sample {i}: {e}\")\n",
    "                ground_truth_texts.append(\"[DECODING ERROR GT]\")\n",
    "        else:\n",
    "             ground_truth_texts.append(\"\")\n",
    "    return ground_truth_texts"
   ],
   "id": "d6cc2aab95d72a43",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T23:47:36.960614Z",
     "start_time": "2025-04-06T23:46:23.212050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === VIẾT LẠI: Đánh giá cuối cùng trên tập Test ===\n",
    "\n",
    "print(\"\\n===== Bắt đầu Đánh giá Cuối cùng trên Tập Test =====\")\n",
    "\n",
    "# --- Khởi tạo biến cho đánh giá ---\n",
    "model_to_evaluate = None\n",
    "checkpoint_loaded_successfully = False\n",
    "char_to_int_eval = None\n",
    "int_to_char_eval = None\n",
    "blank_idx_eval = None\n",
    "num_classes_eval = None\n",
    "\n",
    "# --- Kiểm tra điều kiện tiên quyết ---\n",
    "if jiwer is None:\n",
    "    print(\"Lỗi: Thư viện jiwer không khả dụng.\")\n",
    "elif 'test_loader_htr' not in globals() or test_loader_htr is None:\n",
    "    print(\"Lỗi: test_loader_htr không được định nghĩa hoặc rỗng.\")\n",
    "elif 'CHECKPOINT_PATH_HTR' not in globals() or not CHECKPOINT_PATH_HTR:\n",
    "    print(\"Lỗi: Đường dẫn checkpoint CHECKPOINT_PATH_HTR chưa được định nghĩa.\")\n",
    "elif 'EXPECTED_ARCHITECTURE' not in globals() or not EXPECTED_ARCHITECTURE:\n",
    "    print(\"Lỗi: Tên kiến trúc EXPECTED_ARCHITECTURE chưa được định nghĩa.\")\n",
    "elif 'CRNN' not in globals() or not callable(CRNN):\n",
    "     print(\"Lỗi: Class CRNN chưa được định nghĩa.\")\n",
    "elif 'BLANK_TOKEN' not in globals():\n",
    "     print(\"Lỗi: Biến BLANK_TOKEN chưa được định nghĩa.\")\n",
    "else:\n",
    "    # --- Tải Checkpoint và Model ---\n",
    "    load_path = CHECKPOINT_PATH_HTR # Sử dụng path đã định nghĩa cho training\n",
    "    print(f\"Đường dẫn checkpoint để đánh giá: {load_path}\")\n",
    "\n",
    "    if os.path.exists(load_path):\n",
    "        try:\n",
    "            print(f\"Đang tải checkpoint từ: {load_path}\")\n",
    "            checkpoint = torch.load(load_path, map_location=device)\n",
    "            print(\"Tải file checkpoint thành công.\")\n",
    "\n",
    "            # 1. Kiểm tra kiến trúc\n",
    "            loaded_architecture = checkpoint.get('architecture')\n",
    "            if loaded_architecture != EXPECTED_ARCHITECTURE:\n",
    "                print(f\"\\nLỖI KIẾN TRÚC: Checkpoint là '{loaded_architecture}', nhưng đang cần '{EXPECTED_ARCHITECTURE}'.\")\n",
    "            else:\n",
    "                print(f\"-> Kiến trúc checkpoint khớp: '{loaded_architecture}'\")\n",
    "\n",
    "                # 2. Load Character Map (Bắt buộc)\n",
    "                if 'char_to_int' in checkpoint:\n",
    "                    char_to_int_eval = checkpoint['char_to_int']\n",
    "                    int_to_char_eval = {v: k for k, v in char_to_int_eval.items()}\n",
    "                    num_classes_eval = len(char_to_int_eval)\n",
    "                    blank_idx_eval = char_to_int_eval.get(BLANK_TOKEN)\n",
    "                    if blank_idx_eval is None:\n",
    "                         print(f\"Lỗi: '{BLANK_TOKEN}' không tìm thấy trong char_to_int của checkpoint.\")\n",
    "                    else:\n",
    "                         print(f\"-> Load thành công char_map ({num_classes_eval} lớp, blank={blank_idx_eval}).\")\n",
    "\n",
    "                         # 3. Khởi tạo Model đúng cấu trúc\n",
    "                         print(\"--> Khởi tạo cấu trúc model CRNN...\")\n",
    "                         model_to_evaluate = CRNN(num_classes=num_classes_eval).to(device)\n",
    "                         # CRNN() ở đây phải là class đã được định nghĩa ở cell trước với cấu trúc CNN cắt bớt đúng\n",
    "\n",
    "                         # 4. Load State Dict (nơi thường xảy ra lỗi mismatch)\n",
    "                         print(\"--> Đang tải model_state_dict...\")\n",
    "                         try:\n",
    "                             model_to_evaluate.load_state_dict(checkpoint['model_state_dict'])\n",
    "                             print(\"Tải trọng số model thành công.\")\n",
    "                             model_to_evaluate.eval() # Chuyển sang chế độ đánh giá\n",
    "                             checkpoint_loaded_successfully = True # Đánh dấu thành công\n",
    "                         except RuntimeError as rte_load:\n",
    "                              print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                              print(f\"LỖI RUNTIME khi load state_dict: {rte_load}\")\n",
    "                              print(\"===> Điều này có nghĩa kiến trúc model hiện tại KHÔNG KHỚP với checkpoint.\")\n",
    "                              print(\"===> Đảm bảo cell định nghĩa class CRNN và cell training đã dùng CÙNG MỘT cấu trúc CNN cắt bớt.\")\n",
    "                              print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
    "                         except KeyError as ke_load:\n",
    "                              print(f\"\\nLỗi KeyError khi load state_dict: {ke_load}. Checkpoint có thể bị lỗi.\")\n",
    "\n",
    "                else:\n",
    "                    print(\"Lỗi: Không tìm thấy 'char_to_int' trong checkpoint.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Lỗi: Không tìm thấy file checkpoint tại {load_path}.\")\n",
    "        except Exception as e_load_outer:\n",
    "            print(f\"Lỗi không xác định khi tải checkpoint: {e_load_outer}\")\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(f\"Lỗi: File checkpoint không tồn tại tại {load_path}.\")\n",
    "\n",
    "\n",
    "    # --- Chạy Đánh giá nếu mọi thứ sẵn sàng ---\n",
    "    if checkpoint_loaded_successfully and model_to_evaluate is not None and test_loader_htr is not None:\n",
    "        print(\"\\nBắt đầu chạy vòng lặp đánh giá trên test loader...\")\n",
    "        all_ground_truths = []\n",
    "        all_predictions = []\n",
    "        evaluation_progress_bar = tqdm(test_loader_htr, desc=\"Evaluating Test Set\", unit=\"batch\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_data_eval in evaluation_progress_bar:\n",
    "                # Bỏ qua batch lỗi từ collate_fn\n",
    "                if batch_data_eval is None or batch_data_eval[0] is None:\n",
    "                    continue\n",
    "\n",
    "                # Giải nén batch\n",
    "                images_eval, padded_labels_eval, _, label_lengths_eval = batch_data_eval\n",
    "                images_eval = images_eval.to(device)\n",
    "\n",
    "                try:\n",
    "                    # Dự đoán\n",
    "                    outputs_eval = model_to_evaluate(images_eval)\n",
    "\n",
    "                    # Giải mã Dự đoán (Greedy) - dùng map và blank index đã load\n",
    "                    predicted_texts = decode_batch(outputs_eval.cpu(), int_to_char_eval, blank_idx_eval)\n",
    "\n",
    "                    # Giải mã Nhãn gốc - dùng map đã load\n",
    "                    ground_truth_texts = decode_padded_labels(padded_labels_eval.cpu(), label_lengths_eval.cpu(), int_to_char_eval)\n",
    "\n",
    "                    # Lưu kết quả\n",
    "                    all_ground_truths.extend(ground_truth_texts)\n",
    "                    all_predictions.extend(predicted_texts)\n",
    "\n",
    "                except Exception as e_inf:\n",
    "                     print(f\"\\nLỗi trong quá trình inference hoặc decode batch: {e_inf}\")\n",
    "                     # Có thể in thêm thông tin batch để debug\n",
    "\n",
    "        # --- Tính toán WER và CER ---\n",
    "        print(\"\\nHoàn thành dự đoán. Bắt đầu tính toán WER/CER...\")\n",
    "        if not all_ground_truths or not all_predictions:\n",
    "             print(\"Lỗi: Không có kết quả dự đoán hoặc nhãn gốc để đánh giá.\")\n",
    "        elif len(all_ground_truths) != len(all_predictions):\n",
    "             print(f\"Lỗi: Số lượng nhãn gốc ({len(all_ground_truths)}) != dự đoán ({len(all_predictions)}).\")\n",
    "        else:\n",
    "            try:\n",
    "                # Áp dụng transform chuẩn hóa\n",
    "                transformed_gt = [jiwer_transform(s) for s in all_ground_truths]\n",
    "                transformed_pred = [jiwer_transform(s) for s in all_predictions]\n",
    "\n",
    "                # Tính toán\n",
    "                wer_score = jiwer.wer(transformed_gt, transformed_pred)\n",
    "                cer_score = jiwer.cer(transformed_gt, transformed_pred)\n",
    "\n",
    "                print(\"\\n===== Kết quả Đánh giá Cuối cùng =====\")\n",
    "                print(f\"Số mẫu đánh giá: {len(all_ground_truths)}\")\n",
    "                print(f\"Word Error Rate (WER): {wer_score:.4f}\")\n",
    "                print(f\"Character Error Rate (CER): {cer_score:.4f}\")\n",
    "\n",
    "                # In ví dụ\n",
    "                print(\"\\nVí dụ dự đoán:\")\n",
    "                num_examples = min(5, len(all_ground_truths))\n",
    "                for i in range(num_examples):\n",
    "                    print(\"-\" * 20)\n",
    "                    print(f\"GT [{i}]: {all_ground_truths[i]}\")\n",
    "                    print(f\"PD [{i}]: {all_predictions[i]}\")\n",
    "                print(\"-\" * 20)\n",
    "\n",
    "            except Exception as e_eval:\n",
    "                print(f\"\\nLỗi khi tính toán WER/CER bằng jiwer: {e_eval}\")\n",
    "\n",
    "    else:\n",
    "         print(\"\\nKhông thể thực hiện đánh giá: Model không được load thành công, hoặc test loader/char map không hợp lệ.\")\n",
    "\n",
    "# --- Dọn dẹp cuối cùng ---\n",
    "if 'model_to_evaluate' in locals(): del model_to_evaluate\n",
    "if 'checkpoint' in locals(): del checkpoint\n",
    "gc.collect()\n",
    "if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n===== Script HTR hoàn tất =====\")"
   ],
   "id": "ec22df05512344f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Bắt đầu Đánh giá Cuối cùng trên Tập Test =====\n",
      "Đường dẫn checkpoint để đánh giá: G:\\Compvision Final\\pythonProject\\checkpoint_htr_word_effnet_trunc_early.pth\n",
      "Đang tải checkpoint từ: G:\\Compvision Final\\pythonProject\\checkpoint_htr_word_effnet_trunc_early.pth\n",
      "Tải file checkpoint thành công.\n",
      "-> Kiến trúc checkpoint khớp: 'EfficientNetB0_Truncated_Early_CRNN'\n",
      "-> Load thành công char_map (144 lớp, blank=0).\n",
      "--> Khởi tạo cấu trúc model CRNN...\n",
      "Đã xây dựng CNN bị cắt bớt SỚM HƠN từ EfficientNet-B0 pre-trained.\n",
      "Input size cho LSTM sẽ là: 24\n",
      "--- Khởi tạo CRNN với EfficientNet-B0 BỊ CẮT BỚT SỚM HƠN ---\n",
      "CNN Backbone: Truncated EfficientNet-B0 Features (ví dụ: [:3])\n",
      "CNN Output Channels (to RNN): 24\n",
      "CNN Output Width (SeqLen for RNN - đã tính): 96\n",
      "RNN Hidden Size: 256\n",
      "RNN Num Layers: 2\n",
      "Output Classes (incl. blank): 144\n",
      "------------------------------------------------------\n",
      "--> Đang tải model_state_dict...\n",
      "Tải trọng số model thành công.\n",
      "\n",
      "Bắt đầu chạy vòng lặp đánh giá trên test loader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set: 100%|██████████| 208/208 [01:12<00:00,  2.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hoàn thành dự đoán. Bắt đầu tính toán WER/CER...\n",
      "\n",
      "===== Kết quả Đánh giá Cuối cùng =====\n",
      "Số mẫu đánh giá: 6643\n",
      "Word Error Rate (WER): 0.9077\n",
      "Character Error Rate (CER): 0.4470\n",
      "\n",
      "Ví dụ dự đoán:\n",
      "--------------------\n",
      "GT [0]: trong\n",
      "PD [0]: tng\n",
      "--------------------\n",
      "GT [1]: Mai\n",
      "PD [1]: ki\n",
      "--------------------\n",
      "GT [2]: ở\n",
      "PD [2]: ở\n",
      "--------------------\n",
      "GT [3]: nồng\n",
      "PD [3]: nng\n",
      "--------------------\n",
      "GT [4]: nghĩa\n",
      "PD [4]: nht\n",
      "--------------------\n",
      "\n",
      "===== Script HTR hoàn tất =====\n"
     ]
    }
   ],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
