{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T10:16:14.663155Z",
     "start_time": "2025-04-04T10:16:13.442052Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sns\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:19:10.240159Z",
     "start_time": "2025-04-04T10:19:10.234157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Đường dẫn thư mục dữ liệu\n",
    "data_dir = r\"E:\\HANDS-VNOnDB\"\n",
    "folders = [\"InkData_word\", \"InkData_line\", \"InkData_paragraph\"]\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"Thư mục {folder_path} tồn tại.\")\n",
    "    else:\n",
    "        print(f\"LỖI: Thư mục {folder_path} không tồn tại!\")"
   ],
   "id": "140b25e42bce0ef8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thư mục E:\\HANDS-VNOnDB\\InkData_word tồn tại.\n",
      "Thư mục E:\\HANDS-VNOnDB\\InkData_line tồn tại.\n",
      "Thư mục E:\\HANDS-VNOnDB\\InkData_paragraph tồn tại.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:21:02.570073Z",
     "start_time": "2025-04-04T10:21:02.229854Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             id  label               document_id line_id  \\\n",
      "0  20140603_0003_BCCTC_tg_0_0_0    Bản  20140603_0003_BCCTC_tg_0       0   \n",
      "1  20140603_0003_BCCTC_tg_0_0_1   chất  20140603_0003_BCCTC_tg_0       0   \n",
      "2  20140603_0003_BCCTC_tg_0_0_2    của  20140603_0003_BCCTC_tg_0       0   \n",
      "3  20140603_0003_BCCTC_tg_0_0_3  thành  20140603_0003_BCCTC_tg_0       0   \n",
      "4  20140603_0003_BCCTC_tg_0_0_4   công  20140603_0003_BCCTC_tg_0       0   \n",
      "\n",
      "  word_id  \n",
      "0       0  \n",
      "1       1  \n",
      "2       2  \n",
      "3       3  \n",
      "4       4  \n"
     ]
    }
   ],
   "execution_count": 11,
   "source": [
    "# 3. Chuẩn hóa file gán nhãn\n",
    "\n",
    "def split_id(df, id_col=\"id\"):\n",
    "    df[['document_id', 'line_id', 'word_id']] = df[id_col].str.rsplit('_', n=2, expand=True)\n",
    "    return df.head()\n",
    "\n",
    "print(split_id(pd.read_csv(os.path.join(data_dir, \"InkData_word.csv\"))))"
   ],
   "id": "cc49f1d91217127f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T10:23:54.427339Z",
     "start_time": "2025-04-04T10:23:53.367405Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lưu file: E:\\HANDS-VNOnDB\\normalized_InkData_word.csv\n",
      "Lưu file: E:\\HANDS-VNOnDB\\normalized_InkData_line.csv\n",
      "Lưu file: E:\\HANDS-VNOnDB\\normalized_InkData_paragraph.csv\n"
     ]
    }
   ],
   "execution_count": 14,
   "source": [
    "# 5. Lưu file gán nhãn đã chuẩn hóa\n",
    "def save_normalized_labels(file_name):\n",
    "    path = os.path.join(data_dir, file_name)\n",
    "    df = pd.read_csv(path)\n",
    "    df[['document_id', 'line_id', 'word_id']] = df['id'].str.rsplit('_', n=2, expand=True)\n",
    "    save_path = os.path.join(data_dir, f\"normalized_{file_name}\")\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Lưu file: {save_path}\")\n",
    "\n",
    "# Lưu cả ba file\n",
    "save_normalized_labels(\"InkData_word.csv\")\n",
    "save_normalized_labels(\"InkData_line.csv\")\n",
    "save_normalized_labels(\"InkData_paragraph.csv\")"
   ],
   "id": "f3f6aa2bda6cf44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:00:27.972606Z",
     "start_time": "2025-04-05T08:00:27.952603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Chuyển ảnh sang grayscale, chuẩn hóa pixel và resize\n",
    "def convert_to_grayscale_and_resize(image_path, target_size=(640, 640)):\n",
    "    with Image.open(image_path) as img:\n",
    "        # img_gray = img.convert(\"L\")  # Chuyển sang grayscale\n",
    "        img_resized = img.resize(target_size)  # Resize ảnh về kích thước (640, 640)\n",
    "        img_array = np.array(img_resized) / 255.0  # Chuẩn hóa pixel về [0,1]\n",
    "    return img_resized, img_array"
   ],
   "id": "af8cf9317a9c3658",
   "outputs": [],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:01:51.872757Z",
     "start_time": "2025-04-05T08:01:51.854757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def process_and_save_images(input_folder, output_folder, target_size=(640, 640)):\n",
    "    # Tạo thư mục đầu ra nếu chưa có\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Lấy danh sách ảnh trong thư mục đầu vào\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg'))]\n",
    "\n",
    "    # Thêm thanh tiến trình với tqdm\n",
    "    for img_file in tqdm(image_files, desc=\"Processing images\", unit=\"image\"):\n",
    "        img_path = os.path.join(input_folder, img_file)\n",
    "\n",
    "        # Chuyển ảnh sang grayscale, resize và chuẩn hóa\n",
    "        processed_img, _ = convert_to_grayscale_and_resize(img_path, target_size)\n",
    "\n",
    "        # Lưu ảnh đã xử lý vào thư mục đầu ra\n",
    "        output_img_path = os.path.join(output_folder, img_file)\n",
    "        processed_img.save(output_img_path)\n",
    "\n",
    "        # # Kiểm tra chế độ ảnh\n",
    "        # check_image_mode(img_path)\n",
    "        # print(f\"Ảnh đã được lưu tại: {output_img_path}\")\n",
    "\n",
    "\n",
    "# Thư mục đầu vào và đầu ra\n",
    "input_folder = r\"E:\\HANDS-VNOnDB\\InkData_word\"  # Đổi thành thư mục chứa ảnh gốc\n",
    "output_folder = r\"E:\\HANDS-VNOnDB\\Processed_Images_Words\"  # Đổi thành thư mục lưu ảnh đã xử lý"
   ],
   "id": "2c47502ec6103bdb",
   "outputs": [],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:02:10.323426500Z",
     "start_time": "2025-04-05T08:01:55.029748Z"
    }
   },
   "cell_type": "code",
   "source": "process_and_save_images(input_folder, output_folder)",
   "id": "36e16304a5a3733d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   1%|          | 646/110746 [00:15<43:18, 42.38image/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[241], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mprocess_and_save_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_folder\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[240], line 18\u001B[0m, in \u001B[0;36mprocess_and_save_images\u001B[1;34m(input_folder, output_folder, target_size)\u001B[0m\n\u001B[0;32m     15\u001B[0m img_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(input_folder, img_file)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Chuyển ảnh sang grayscale, resize và chuẩn hóa\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m processed_img, _ \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_to_grayscale_and_resize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Lưu ảnh đã xử lý vào thư mục đầu ra\u001B[39;00m\n\u001B[0;32m     21\u001B[0m output_img_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_folder, img_file)\n",
      "Cell \u001B[1;32mIn[235], line 3\u001B[0m, in \u001B[0;36mconvert_to_grayscale_and_resize\u001B[1;34m(image_path, target_size)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mconvert_to_grayscale_and_resize\u001B[39m(image_path, target_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m640\u001B[39m, \u001B[38;5;241m640\u001B[39m)):\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Image\u001B[38;5;241m.\u001B[39mopen(image_path) \u001B[38;5;28;01mas\u001B[39;00m img:\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;66;03m# img_gray = img.convert(\"L\")  # Chuyển sang grayscale\u001B[39;00m\n\u001B[0;32m      5\u001B[0m         img_resized \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mresize(target_size)  \u001B[38;5;66;03m# Resize ảnh về kích thước (640, 640)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m         img_array \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(img_resized) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.0\u001B[39m  \u001B[38;5;66;03m# Chuẩn hóa pixel về [0,1]\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\PIL\\Image.py:614\u001B[0m, in \u001B[0;36mImage.__exit__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    611\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp:\n\u001B[0;32m    612\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m--> 614\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m    615\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfp\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    616\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_exclusive_fp\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:02:25.034162Z",
     "start_time": "2025-04-05T08:02:25.015157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Chuyển ảnh sang grayscale, chuẩn hóa pixel và resize\n",
    "def convert_to_grayscale_and_resize_lines(image_path, target_size=(740, 320)):\n",
    "    with Image.open(image_path) as img:\n",
    "        # img_gray = img.convert(\"L\")  # Chuyển sang grayscale\n",
    "        img_resized = img.resize(target_size)  # Resize ảnh về kích thước (640, 640)\n",
    "        img_array = np.array(img_resized) / 255.0  # Chuẩn hóa pixel về [0,1]\n",
    "    return img_resized, img_array"
   ],
   "id": "6da505fd1e3b7f89",
   "outputs": [],
   "execution_count": 242
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:02:48.024574Z",
     "start_time": "2025-04-05T08:02:48.005508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hàm xử lý tất cả ảnh trong thư mục và lưu vào thư mục mới\n",
    "from tqdm import tqdm\n",
    "def process_and_save_images_line(input_folder, output_folder, target_size=(640, 640)):\n",
    "    # Tạo thư mục đầu ra nếu chưa có\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Lấy danh sách ảnh trong thư mục đầu vào\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg'))]\n",
    "    \n",
    "    # Dùng tqdm để theo dõi tiến trình\n",
    "    for img_file in tqdm(image_files, desc=\"Đang xử lý ảnh\", unit=\"ảnh\"):\n",
    "        img_path = os.path.join(input_folder, img_file)\n",
    "        \n",
    "        # Chuyển ảnh sang grayscale, resize và chuẩn hóa\n",
    "        processed_img, _ = convert_to_grayscale_and_resize_lines(img_path, target_size)\n",
    "        \n",
    "        # Lưu ảnh đã xử lý vào thư mục đầu ra\n",
    "        output_img_path = os.path.join(output_folder, img_file)\n",
    "        processed_img.save(output_img_path)"
   ],
   "id": "384bf2ea7d68e4b",
   "outputs": [],
   "execution_count": 244
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:06:53.015157Z",
     "start_time": "2025-04-05T08:02:49.663877Z"
    }
   },
   "cell_type": "code",
   "source": "process_and_save_images_line(r\"E:\\HANDS-VNOnDB\\InkData_line\", r\"E:\\HANDS-VNOnDB\\Processed_Images_Lines\")",
   "id": "d3598c7fe0fe1f72",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang xử lý ảnh: 100%|██████████| 7296/7296 [04:03<00:00, 29.99ảnh/s]\n"
     ]
    }
   ],
   "execution_count": 245
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T11:16:38.762105Z",
     "start_time": "2025-04-04T11:16:18.564322Z"
    }
   },
   "cell_type": "code",
   "source": "process_and_save_images(r\"E:\\HANDS-VNOnDB\\InkData_paragraph\", r\"E:\\HANDS-VNOnDB\\Processed_Images_Paragraphs\")",
   "id": "f9e12b37f7ac6a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang xử lý ảnh: 100%|██████████| 1144/1144 [00:20<00:00, 56.71ảnh/s]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T03:29:05.331896Z",
     "start_time": "2025-04-05T03:29:05.104783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# # Đọc các file gán nhãn\n",
    "# word_labels_df = pd.read_csv(r\"E:\\HANDS-VNOnDB\\reduced_normalized_InkData_word.csv\")\n",
    "# line_labels_df = pd.read_csv(r\"E:\\HANDS-VNOnDB\\reduced_normalized_InkData_line.csv\")\n",
    "# paragraph_labels_df = pd.read_csv(r\"E:\\HANDS-VNOnDB\\reduced_normalized_InkData_paragraph.csv\")\n",
    "# \n",
    "# # Chọn thư mục chứa ảnh đã xử lý\n",
    "# word_images_folder = r\"E:\\HANDS-VNOnDB\\reduced_Processed_Images_Words\"\n",
    "# line_images_folder = r\"E:\\HANDS-VNOnDB\\reduced_Processed_Images_Lines\"\n",
    "# paragraph_images_folder = r\"E:\\HANDS-VNOnDB\\reduced_Processed_Images_Paragraphs\"\n",
    "\n",
    "# # Đọc các file gán nhãn\n",
    "word_labels_df = pd.read_csv(r\"E:\\HANDS-VNOnDB\\normalized_InkData_word.csv\")\n",
    "line_labels_df = pd.read_csv(r\"E:\\HANDS-VNOnDB\\normalized_InkData_line.csv\")\n",
    "paragraph_labels_df = pd.read_csv(r\"E:\\HANDS-VNOnDB\\normalized_InkData_paragraph.csv\")\n",
    "\n",
    "# Chọn thư mục chứa ảnh đã xử lý\n",
    "word_images_folder = r\"E:\\HANDS-VNOnDB\\Processed_Images_Words\"\n",
    "line_images_folder = r\"E:\\HANDS-VNOnDB\\Processed_Images_Lines\"\n",
    "paragraph_images_folder = r\"E:\\HANDS-VNOnDB\\Processed_Images_Paragraphs\""
   ],
   "id": "e9af74a13fcc43a5",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T03:29:07.992959Z",
     "start_time": "2025-04-05T03:29:07.972943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hàm tải ảnh và gán nhãn từ các file CSV\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "# Hàm tải ảnh và gán nhãn từ CSV nhưng không giữ tất cả ảnh trong bộ nhớ\n",
    "def load_images_and_labels(image_folder, labels_df, id_column=\"id\"):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in tqdm(labels_df.iterrows(), total=labels_df.shape[0], desc=\"Đọc và xử lý ảnh\"):\n",
    "        img_filename = f\"{row[id_column]}.png\"\n",
    "        img_path = os.path.join(image_folder, img_filename)\n",
    "        \n",
    "        if os.path.exists(img_path):  # Kiểm tra xem ảnh có tồn tại không\n",
    "            img = np.array(Image.open(img_path))  # Chỉ load từng ảnh một\n",
    "            \n",
    "            # TODO: Xử lý ảnh ở đây (nếu cần)\n",
    "\n",
    "            del img  # Giải phóng bộ nhớ ngay sau khi xử lý\n",
    "            gc.collect()\n",
    "\n",
    "            # Chỉ lưu đường dẫn và nhãn thay vì giữ ảnh trong RAM\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(row[id_column])\n",
    "    \n",
    "    return image_paths, np.array(labels)  # Tr"
   ],
   "id": "5f8d368152735566",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T03:30:03.131957200Z",
     "start_time": "2025-04-05T03:29:12.515450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tải ảnh và nhãn từ các thư mục\n",
    "X_word, y_word = load_images_and_labels(word_images_folder, word_labels_df)\n",
    "X_line, y_line = load_images_and_labels(line_images_folder, line_labels_df)\n",
    "X_paragraph, y_paragraph = load_images_and_labels(paragraph_images_folder, paragraph_labels_df)"
   ],
   "id": "577167d90fa872c8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đọc và xử lý ảnh:   0%|          | 279/110746 [00:50<5:34:41,  5.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[104], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Tải ảnh và nhãn từ các thư mục\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m X_word, y_word \u001B[38;5;241m=\u001B[39m \u001B[43mload_images_and_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword_images_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword_labels_df\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m X_line, y_line \u001B[38;5;241m=\u001B[39m load_images_and_labels(line_images_folder, line_labels_df)\n\u001B[0;32m      4\u001B[0m X_paragraph, y_paragraph \u001B[38;5;241m=\u001B[39m load_images_and_labels(paragraph_images_folder, paragraph_labels_df)\n",
      "Cell \u001B[1;32mIn[103], line 19\u001B[0m, in \u001B[0;36mload_images_and_labels\u001B[1;34m(image_folder, labels_df, id_column)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# TODO: Xử lý ảnh ở đây (nếu cần)\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m img  \u001B[38;5;66;03m# Giải phóng bộ nhớ ngay sau khi xử lý\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[43mgc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Chỉ lưu đường dẫn và nhãn thay vì giữ ảnh trong RAM\u001B[39;00m\n\u001B[0;32m     22\u001B[0m image_paths\u001B[38;5;241m.\u001B[39mappend(img_path)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:24:11.873124Z",
     "start_time": "2025-04-05T02:24:11.862121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chia tập dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_line_train, X_line_test, y_line_train, y_line_test = train_test_split(X_line, y_line, test_size=0.2, random_state=42)\n",
    "# Kiểm tra số lượng mẫu trong mỗi tập\n",
    "print(f\"Số lượng mẫu trong tập huấn luyện: {len(X_line_train)}\")\n",
    "print(f\"Số lượng mẫu trong tập kiểm tra: {len(X_line_test)}\")"
   ],
   "id": "a968613a2cc54239",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng mẫu trong tập huấn luyện: 1751\n",
      "Số lượng mẫu trong tập kiểm tra: 438\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T04:01:43.370406Z",
     "start_time": "2025-04-05T04:01:43.339320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chia tập dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_word_train, X_word_test, y_word_train, y_word_test = train_test_split(X_word, y_word, test_size=0.2, random_state=42)\n",
    "# Kiểm tra số lượng mẫu trong mỗi tập\n",
    "print(f\"Số lượng mẫu trong tập huấn luyện: {len(X_word_train)}\")\n",
    "print(f\"Số lượng mẫu trong tập kiểm tra: {len(X_word_test)}\")"
   ],
   "id": "b5005f7e45074205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng mẫu trong tập huấn luyện: 26579\n",
      "Số lượng mẫu trong tập kiểm tra: 6645\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:24:55.767360Z",
     "start_time": "2025-04-05T02:24:55.738356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lưu tập train\n",
    "train_df = pd.DataFrame({\"image_path\": X_line_train, \"label\": y_line_train})\n",
    "train_df.to_csv(r\"E:\\HANDS-VNOnDB\\train_lines.csv\", index=False)\n",
    "\n",
    "# Lưu tập test\n",
    "test_df = pd.DataFrame({\"image_path\": X_line_test, \"label\": y_line_test})\n",
    "test_df.to_csv(r\"E:\\HANDS-VNOnDB\\test_lines.csv\", index=False)"
   ],
   "id": "4a0e78b235592ccd",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T04:02:45.479721Z",
     "start_time": "2025-04-05T04:02:45.389850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lưu tập train word\n",
    "train_df = pd.DataFrame({\"image_path\": X_word_train, \"label\": y_word_train})\n",
    "train_df.to_csv(r\"E:\\HANDS-VNOnDB\\train_words.csv\", index=False)\n",
    "\n",
    "# Lưu tập test word\n",
    "test_df = pd.DataFrame({\"image_path\": X_word_test, \"label\": y_word_test})\n",
    "test_df.to_csv(r\"E:\\HANDS-VNOnDB\\test_words.csv\", index=False)"
   ],
   "id": "ce4666edfbea3df2",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T04:02:49.751482Z",
     "start_time": "2025-04-05T04:02:49.746511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# B1: Tiền xử lý ảnh đầu vào (resize về 128x32, chuẩn hóa pixel, chuyển sang tensor)\n",
    "from torchvision import transforms\n",
    "\n",
    "# Áp dụng resize và chuẩn hóa pixel về [0, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 32)),     # Resize ảnh về (32, 128)\n",
    "    transforms.ToTensor(),            # Chuyển ảnh về tensor (C, H, W) và chia pixel cho 255\n",
    "])\n"
   ],
   "id": "65de5f34de70d1a4",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T02:22:21.936074Z",
     "start_time": "2025-04-05T02:22:21.917070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#line\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Mở ảnh\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Nếu có transform, áp dụng vào ảnh\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ],
   "id": "582d0d92679959f3",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:43:22.018019Z",
     "start_time": "2025-04-05T07:43:21.996020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#lines\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Kết hợp nhãn train và test\n",
    "all_labels_lines = np.concatenate([y_line_train, y_line_test])\n",
    "\n",
    "# Fit LabelEncoder trên tất cả nhãn\n",
    "le_line = LabelEncoder()\n",
    "le_line.fit(all_labels_lines)\n",
    "\n",
    "# Encode nhãn train và test\n",
    "y_line_train_enc = le_line.transform(y_line_train)  # Chỉ dùng transform, không fit lại\n",
    "y_line_test_enc  = le_line.transform(y_line_test)\n",
    "\n",
    "# Tạo Dataset\n",
    "train_dataset_line = CustomDataset(image_paths=X_line_train, labels=y_line_train_enc, transform=transform)\n",
    "test_dataset_line = CustomDataset(image_paths=X_line_test, labels=y_line_test_enc, transform=transform)\n",
    "\n",
    "# Tạo Dataloader\n",
    "train_loader_line = DataLoader(train_dataset_line, batch_size=32, shuffle=True)\n",
    "test_loader_line = DataLoader(test_dataset_line, batch_size=32, shuffle=False)"
   ],
   "id": "ead92956b3163d4d",
   "outputs": [],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:43:23.532728Z",
     "start_time": "2025-04-05T07:43:23.394131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#words\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Kết hợp nhãn train và test\n",
    "all_labels_words = np.concatenate([y_word_train, y_word_test])\n",
    "\n",
    "# Fit LabelEncoder trên tất cả nhãn\n",
    "le_word = LabelEncoder()\n",
    "le_word.fit(all_labels_words)\n",
    "\n",
    "# Encode nhãn train và test\n",
    "y_word_train_enc = le_word.transform(y_word_train)  # Chỉ dùng transform, không fit lại\n",
    "y_word_test_enc  = le_word.transform(y_word_test)\n",
    "\n",
    "# Tạo Dataset\n",
    "train_dataset_word = CustomDataset(image_paths=X_word_train, labels=y_word_train_enc, transform=transform)\n",
    "test_dataset_word = CustomDataset(image_paths=X_word_test, labels=y_word_test_enc, transform=transform)\n",
    "\n",
    "# Tạo Dataloader\n",
    "train_loader_word = DataLoader(train_dataset_word, batch_size=32, shuffle=True)\n",
    "test_loader_word = DataLoader(test_dataset_word, batch_size=32, shuffle=False)"
   ],
   "id": "24b3de5978ecefd8",
   "outputs": [],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:43:25.176406Z",
     "start_time": "2025-04-05T07:43:25.160357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Số nhãn duy nhất trong all_labels: {len(set(all_labels_lines))}\")\n",
    "print(f\"Số nhãn duy nhất trong y_line_train: {len(set(y_line_train))}\")\n",
    "print(f\"Số nhãn duy nhất trong y_line_test: {len(set(y_line_test))}\")\n",
    "print(f\"Giá trị nhỏ nhất trong y_line_train_enc: {min(y_line_train_enc)}\")\n",
    "print(f\"Giá trị lớn nhất trong y_line_train_enc: {max(y_line_train_enc)}\")\n",
    "print(f\"Giá trị nhỏ nhất trong y_line_test_enc: {min(y_line_test_enc)}\")\n",
    "print(f\"Giá trị lớn nhất trong y_line_test_enc: {max(y_line_test_enc)}\")"
   ],
   "id": "f4c6041ba55a8050",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số nhãn duy nhất trong all_labels: 2189\n",
      "Số nhãn duy nhất trong y_line_train: 1751\n",
      "Số nhãn duy nhất trong y_line_test: 438\n",
      "Giá trị nhỏ nhất trong y_line_train_enc: 0\n",
      "Giá trị lớn nhất trong y_line_train_enc: 2188\n",
      "Giá trị nhỏ nhất trong y_line_test_enc: 1\n",
      "Giá trị lớn nhất trong y_line_test_enc: 2182\n"
     ]
    }
   ],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:43:27.321800Z",
     "start_time": "2025-04-05T07:43:27.271262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Số nhãn duy nhất trong all_labels: {len(set(all_labels_words))}\")\n",
    "print(f\"Số nhãn duy nhất trong y_word_train: {len(set(y_word_train))}\")\n",
    "print(f\"Số nhãn duy nhất trong y_word_test: {len(set(y_word_test))}\")\n",
    "print(f\"Giá trị nhỏ nhất trong y_word_train_enc: {min(y_word_train_enc)}\")\n",
    "print(f\"Giá trị lớn nhất trong y_word_train_enc: {max(y_word_train_enc)}\")\n",
    "print(f\"Giá trị nhỏ nhất trong y_word_test_enc: {min(y_word_test_enc)}\")\n",
    "print(f\"Giá trị lớn nhất trong y_word_test_enc: {max(y_word_test_enc)}\")"
   ],
   "id": "4b06e97aa26297bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số nhãn duy nhất trong all_labels: 33224\n",
      "Số nhãn duy nhất trong y_word_train: 26579\n",
      "Số nhãn duy nhất trong y_word_test: 6645\n",
      "Giá trị nhỏ nhất trong y_word_train_enc: 0\n",
      "Giá trị lớn nhất trong y_word_train_enc: 33223\n",
      "Giá trị nhỏ nhất trong y_word_test_enc: 2\n",
      "Giá trị lớn nhất trong y_word_test_enc: 33218\n"
     ]
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T05:16:26.020585Z",
     "start_time": "2025-04-05T05:16:25.822531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in train_loader_word:\n",
    "    print(type(batch), len(batch))  # In kiểu dữ liệu và độ dài của batch\n",
    "    break"
   ],
   "id": "c32f87ff624bdd61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 2\n"
     ]
    }
   ],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T05:27:06.397802Z",
     "start_time": "2025-04-05T05:27:06.392801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ],
   "id": "fa5b09e6f345cb4a",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:43:49.220207Z",
     "start_time": "2025-04-05T07:43:49.133706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#line\n",
    "import torchvision.models as models\n",
    "\n",
    "# Tạo mô hình MobileNetV2\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Sửa số lớp thành len(le.classes_) thay vì len(set(y_line_train))\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(le_line.classes_))\n",
    "\n",
    "# Di chuyển mô hình sang GPU nếu có\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "id": "44ea7814dc9aa072",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "G:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=2189, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:45:48.502401Z",
     "start_time": "2025-04-05T07:45:48.254078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#word\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "# Tạo mô hình MobileNetV2\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Sửa số lớp thành len(le.classes_) thay vì len(set(y_line_train))\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(le_word.classes_))\n",
    "\n",
    "# Di chuyển mô hình sang GPU nếu có\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "id": "c023c9e5a674bfef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "G:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=33224, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:43:53.287029Z",
     "start_time": "2025-04-05T07:43:53.180529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#line\n",
    "CHECKPOINT_PATH = r\"G:\\Compvision Final\\pythonProject\\checkpoint.pth\"\n",
    "START_EPOCH = 0\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer_line.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    START_EPOCH = checkpoint['epoch'] + 1\n",
    "    print(f\"Tiếp tục từ epoch {START_EPOCH}\")\n",
    "else:\n",
    "    print(\"Bắt đầu huấn luyện từ đầu\")"
   ],
   "id": "d477d0bb834d1a26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiếp tục từ epoch 30\n"
     ]
    }
   ],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:45:51.202148Z",
     "start_time": "2025-04-05T07:45:50.908040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#word\n",
    "CHECKPOINT_PATH = r\"G:\\Compvision Final\\pythonProject\\checkpoint_word.pth\"\n",
    "START_EPOCH = 0\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer_word.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    START_EPOCH = checkpoint['epoch'] + 1\n",
    "    print(f\"Tiếp tục từ epoch {START_EPOCH}\")\n",
    "else:\n",
    "    print(\"Bắt đầu huấn luyện từ đầu\")"
   ],
   "id": "3bce057450b6f9f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiếp tục từ epoch 1\n"
     ]
    }
   ],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:36:16.253058Z",
     "start_time": "2025-04-05T07:36:16.241027Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Số lớp trong mô hình: {model.classifier[1].out_features}\")",
   "id": "40c2aa67bcd7ada8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lớp trong mô hình: 33224\n"
     ]
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:44:10.754404Z",
     "start_time": "2025-04-05T07:44:10.740860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#line\n",
    "# Loss function và optimizer\n",
    "criterion_line = nn.CrossEntropyLoss()\n",
    "optimizer_line = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "num_epochs_line = 40"
   ],
   "id": "a055c9b506f23555",
   "outputs": [],
   "execution_count": 221
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:45:15.281861Z",
     "start_time": "2025-04-05T07:45:15.269774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#word\n",
    "# Loss function và optimizer\n",
    "criterion_word = nn.CrossEntropyLoss()\n",
    "optimizer_word = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "num_epochs_word = 3"
   ],
   "id": "a862628316fd6f19",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:44:36.992351200Z",
     "start_time": "2025-04-05T07:44:12.044865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#line\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for epoch in range(START_EPOCH, num_epochs_line):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader_line, desc=f\"Epoch {epoch+1}/{num_epochs_line}\", ncols=100):\n",
    "        images = images.to(device)\n",
    "        if not torch.is_tensor(labels):\n",
    "            labels = torch.tensor(labels)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer_line.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion_line(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_line.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_preds += labels.size(0)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader_line)\n",
    "    train_accuracy = correct_preds / total_preds\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_line}, Loss: {avg_train_loss}, Accuracy: {train_accuracy}\")\n",
    "    \n",
    "    # Đánh giá trên tập test và thu thập dự đoán\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader_line:\n",
    "            images = images.to(device)\n",
    "            if not torch.is_tensor(labels):\n",
    "                labels = torch.tensor(labels)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_preds += labels.size(0)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_accuracy = correct_preds / total_preds\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "    # Lưu checkpoint sau mỗi epoch\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_line.state_dict(),\n",
    "        'loss': avg_train_loss,\n",
    "    }, CHECKPOINT_PATH)\n",
    "    print(f\"Đã lưu checkpoint tại epoch {epoch+1}\")\n",
    "\n",
    "# Kiểm tra xem có dữ liệu để tính confusion matrix không\n",
    "if len(all_preds) == 0 or len(all_labels) == 0:\n",
    "    print(\"Không có dự đoán hoặc nhãn nào được thu thập từ test_loader!\")\n",
    "else:\n",
    "    # Tính confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Vẽ confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ],
   "id": "71dd162def3880e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/40: 100%|██████████████████████████████████████████████████| 55/55 [00:15<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40, Loss: 5.092802325162021, Accuracy: 0.012564249000571102\n",
      "Test Accuracy: 0.0\n",
      "Đã lưu checkpoint tại epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/40:  38%|███████████████████                               | 21/55 [00:06<00:10,  3.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[222], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(images)\n\u001B[0;32m     20\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion_line(outputs, labels)\n\u001B[1;32m---> 21\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m optimizer_line\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     24\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    824\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    825\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 222
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:54:14.561771700Z",
     "start_time": "2025-04-05T07:45:58.903244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#word\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for epoch in range(START_EPOCH, num_epochs_word):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader_word, desc=f\"Epoch {epoch+1}/{num_epochs_word}\", ncols=100):\n",
    "        images = images.to(device)\n",
    "        if not torch.is_tensor(labels):\n",
    "            labels = torch.tensor(labels)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer_word.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion_word(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_word.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_preds += labels.size(0)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader_word)\n",
    "    train_accuracy = correct_preds / total_preds\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_word}, Loss: {avg_train_loss}, Accuracy: {train_accuracy}\")\n",
    "    \n",
    "    # Đánh giá trên tập test và thu thập dự đoán\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader_word:\n",
    "            images = images.to(device)\n",
    "            if not torch.is_tensor(labels):\n",
    "                labels = torch.tensor(labels)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_preds += labels.size(0)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_accuracy = correct_preds / total_preds\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "    # Lưu checkpoint sau mỗi epoch\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_word.state_dict(),\n",
    "        'loss': avg_train_loss,\n",
    "    }, CHECKPOINT_PATH)\n",
    "    print(f\"Đã lưu checkpoint tại epoch {epoch+1}\")\n",
    "\n",
    "# Kiểm tra xem có dữ liệu để tính confusion matrix không\n",
    "if len(all_preds) == 0 or len(all_labels) == 0:\n",
    "    print(\"Không có dự đoán hoặc nhãn nào được thu thập từ test_loader!\")\n",
    "else:\n",
    "    # Tính confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Vẽ confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ],
   "id": "fb538ef24a238f62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████████████████████████████████████████████| 831/831 [06:35<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 10.386296855270073, Accuracy: 3.76236878738854e-05\n",
      "Test Accuracy: 0.0\n",
      "Đã lưu checkpoint tại epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3:  22%|██████████▊                                       | 179/831 [01:05<03:59,  2.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[234], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(images)\n\u001B[0;32m     20\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion_word(outputs, labels)\n\u001B[1;32m---> 21\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m optimizer_word\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     24\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    824\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    825\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 234
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
