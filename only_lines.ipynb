{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:51:54.827880Z",
     "start_time": "2025-04-05T13:51:49.170160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# === KHÔNG THAY ĐỔI (Imports cơ bản và thêm thư viện cho HTR) ===\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import sns # Không cần thiết cho HTR cơ bản\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import matplotlib.pyplot as plt # Thêm để vẽ đồ thị loss (tùy chọn)"
   ],
   "id": "f04663922ccd9a9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-05T13:51:55.898439Z",
     "start_time": "2025-04-05T13:51:55.882841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Thiết lập đường dẫn) ===\n",
    "# Đường dẫn thư mục dữ liệu\n",
    "data_dir = r\"E:\\HANDS-VNOnDB\" # <--- KIỂM TRA LẠI ĐƯỜNG DẪN NÀY\n",
    "label_file_path = os.path.join(data_dir, \"normalized_InkData_line.csv\") # <--- File chứa cả ID và label text\n",
    "image_folder_original = os.path.join(data_dir, \"InkData_line\")\n",
    "\n",
    "# Thư mục lưu ảnh đã xử lý (resize)\n",
    "image_folder_processed = r\"D:\\HANDS-VNOnDB\\Processed_Images_Lines_HTR\" "
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:51:57.458539Z",
     "start_time": "2025-04-05T13:51:57.380930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Chuẩn hóa file gán nhãn\n",
    "\n",
    "# def split_id(df, id_col=\"id\"):\n",
    "#     df[['document_id', 'line_id', 'word_id']] = df[id_col].str.rsplit('_', n=2, expand=True)\n",
    "#     return df.head()\n",
    "\n",
    "print((pd.read_csv(os.path.join(data_dir, \"normalized_InkData_line.csv\"))))"
   ],
   "id": "42300f39aa46ee87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                id  \\\n",
      "0       20140603_0003_BCCTC_tg_0_0   \n",
      "1       20140603_0003_BCCTC_tg_0_1   \n",
      "2       20140603_0003_BCCTC_tg_0_2   \n",
      "3       20140603_0003_BCCTC_tg_0_3   \n",
      "4       20140603_0003_BCCTC_tg_0_4   \n",
      "...                            ...   \n",
      "7291  20160722_0202_26749_1_tg_6_8   \n",
      "7292  20160722_0202_26749_1_tg_7_0   \n",
      "7293  20160722_0202_26749_1_tg_7_1   \n",
      "7294  20160722_0202_26749_1_tg_7_2   \n",
      "7295  20160722_0202_26749_1_tg_7_3   \n",
      "\n",
      "                                                  label  \\\n",
      "0                               Bản chất của thành công   \n",
      "1     Đã bao giờ bạn tự hỏi thành công là gì mà bao ...   \n",
      "2     chăng đó là kết quả hoàn hảo trong công việc, ...   \n",
      "3     là cách nói khác của từ thành đạt, nghĩa là có...   \n",
      "4     mọi người nể phục? Vậy thì bạn hãy dành chút t...   \n",
      "...                                                 ...   \n",
      "7291        nói thì bao giờ tôi cũng nói có lợi về mình   \n",
      "7292  Các phóng viên đã đặt khá nhiều câu hỏi, nhưng...   \n",
      "7293  từ chối trả lời và nói không phản ứng gì dù những   \n",
      "7294   vấn đề đặt ra ảnh hưởng trực tiếp đến uy tín của   \n",
      "7295                                               ông.   \n",
      "\n",
      "                   document_id  line_id  word_id  \n",
      "0       20140603_0003_BCCTC_tg        0        0  \n",
      "1       20140603_0003_BCCTC_tg        0        1  \n",
      "2       20140603_0003_BCCTC_tg        0        2  \n",
      "3       20140603_0003_BCCTC_tg        0        3  \n",
      "4       20140603_0003_BCCTC_tg        0        4  \n",
      "...                        ...      ...      ...  \n",
      "7291  20160722_0202_26749_1_tg        6        8  \n",
      "7292  20160722_0202_26749_1_tg        7        0  \n",
      "7293  20160722_0202_26749_1_tg        7        1  \n",
      "7294  20160722_0202_26749_1_tg        7        2  \n",
      "7295  20160722_0202_26749_1_tg        7        3  \n",
      "\n",
      "[7296 rows x 5 columns]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:51:59.808542Z",
     "start_time": "2025-04-05T13:51:59.795029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TARGET_IMG_HEIGHT = 32\n",
    "TARGET_IMG_WIDTH = 128"
   ],
   "id": "1740783711f78574",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:52:00.996050Z",
     "start_time": "2025-04-05T13:52:00.984953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_image_htr(image_path, target_size=(TARGET_IMG_WIDTH, TARGET_IMG_HEIGHT)):\n",
    "    \"\"\"Mở ảnh, chuyển grayscale, resize.\"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img_gray = img.convert('L')\n",
    "            img_resized = img_gray.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        return img_resized\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi mở hoặc xử lý ảnh {image_path}: {e}\")\n",
    "        return None"
   ],
   "id": "ca3d7a094f2fb46a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:52:03.174337Z",
     "start_time": "2025-04-05T13:52:03.153249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_and_save_images_htr(input_folder, output_folder, target_size=(TARGET_IMG_WIDTH, TARGET_IMG_HEIGHT)):\n",
    "    \"\"\"Tiền xử lý và lưu ảnh vào thư mục mới.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(f\"Đã tạo thư mục: {output_folder}\")\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg'))]\n",
    "    print(f\"Tìm thấy {len(image_files)} ảnh trong {input_folder}\")\n",
    "\n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "    error_count = 0\n",
    "    for img_file in tqdm(image_files, desc=\"Preprocessing images for HTR\", unit=\"image\"):\n",
    "        img_path = os.path.join(input_folder, img_file)\n",
    "        output_img_path = os.path.join(output_folder, img_file)\n",
    "\n",
    "        if not os.path.exists(output_img_path):\n",
    "            processed_img = preprocess_image_htr(img_path, target_size)\n",
    "            if processed_img:\n",
    "                try:\n",
    "                    processed_img.save(output_img_path)\n",
    "                    processed_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi khi lưu ảnh {output_img_path}: {e}\")\n",
    "                    error_count += 1\n",
    "            else:\n",
    "                 error_count += 1 # Lỗi trong hàm preprocess_image_htr\n",
    "        else:\n",
    "            skipped_count += 1\n",
    "\n",
    "    total_processed_or_skipped = processed_count + skipped_count\n",
    "    print(f\"Hoàn thành tiền xử lý:\")\n",
    "    print(f\"- Đã xử lý mới: {processed_count}\")\n",
    "    print(f\"- Bỏ qua (đã tồn tại): {skipped_count}\")\n",
    "    print(f\"- Lỗi: {error_count}\")\n",
    "    print(f\"- Tổng số ảnh trong thư mục output: {total_processed_or_skipped}\")\n",
    "    print(f\"Ảnh đã xử lý được lưu tại: {output_folder}\")"
   ],
   "id": "1331ea1f6a01dc93",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:52:07.851152Z",
     "start_time": "2025-04-05T13:52:07.277467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chạy tiền xử lý ảnh (chỉ chạy nếu thư mục processed chưa có hoặc muốn ghi đè)\n",
    "run_preprocessing = True # Đặt thành False nếu đã chạy và không muốn chạy lại\n",
    "if run_preprocessing:\n",
    "    process_and_save_images_htr(image_folder_original, image_folder_processed, target_size=(TARGET_IMG_WIDTH, TARGET_IMG_HEIGHT))\n",
    "else:\n",
    "    print(f\"Bỏ qua bước tiền xử lý ảnh, sử dụng ảnh tại: {image_folder_processed}\")\n",
    "    if not os.path.exists(image_folder_processed):\n",
    "        print(f\"CẢNH BÁO: Thư mục ảnh đã xử lý {image_folder_processed} không tồn tại nhưng run_preprocessing=False.\")\n",
    "        exit()\n"
   ],
   "id": "7d8b68ce2342949c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 7296 ảnh trong E:\\HANDS-VNOnDB\\InkData_line\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing images for HTR: 100%|██████████| 7296/7296 [00:00<00:00, 13059.01image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoàn thành tiền xử lý:\n",
      "- Đã xử lý mới: 0\n",
      "- Bỏ qua (đã tồn tại): 7296\n",
      "- Lỗi: 0\n",
      "- Tổng số ảnh trong thư mục output: 7296\n",
      "Ảnh đã xử lý được lưu tại: D:\\HANDS-VNOnDB\\Processed_Images_Lines_HTR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:52:11.329350Z",
     "start_time": "2025-04-05T13:52:11.299841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI (Load nhãn TEXT thay vì ID) ===\n",
    "# Đọc file CSV chứa nhãn\n",
    "try:\n",
    "    labels_df = pd.read_csv(label_file_path)\n",
    "    print(f\"Đã đọc thành công file label: {label_file_path}\")\n",
    "    # print(\"5 dòng đầu tiên của labels_df:\")\n",
    "    # print(labels_df.head())\n",
    "    if 'label' not in labels_df.columns or 'id' not in labels_df.columns:\n",
    "        raise ValueError(\"File CSV phải chứa cột 'id' và 'label'.\")\n",
    "    # Xử lý giá trị NaN trong cột label (thay bằng chuỗi rỗng hoặc bỏ qua)\n",
    "    labels_df['label'] = labels_df['label'].fillna('')\n",
    "    print(f\"Số lượng dòng trong file label: {len(labels_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"LỖI khi đọc hoặc kiểm tra file CSV: {e}\")\n",
    "    exit()"
   ],
   "id": "f07e1eaf28983abe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã đọc thành công file label: E:\\HANDS-VNOnDB\\normalized_InkData_line.csv\n",
      "Số lượng dòng trong file label: 7296\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:52:13.731904Z",
     "start_time": "2025-04-05T13:52:13.716904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Hàm tải đường dẫn ảnh và nhãn TEXT, đảm bảo khớp ID và ảnh tồn tại\n",
    "def load_image_paths_and_text_labels(processed_image_folder, labels_df):\n",
    "    image_paths = []\n",
    "    text_labels = []\n",
    "    missing_images = 0\n",
    "    valid_ids_from_df = set(labels_df['id'])\n",
    "    processed_image_files = os.listdir(processed_image_folder)\n",
    "    processed_ids = set(os.path.splitext(f)[0] for f in processed_image_files if f.endswith(('.png', '.jpg')))\n",
    "\n",
    "    print(f\"Số ID hợp lệ từ CSV: {len(valid_ids_from_df)}\")\n",
    "    print(f\"Số ảnh tìm thấy trong thư mục đã xử lý: {len(processed_ids)}\")\n",
    "\n",
    "    # Lọc DataFrame để chỉ giữ lại các ID có ảnh tương ứng\n",
    "    labels_df_filtered = labels_df[labels_df['id'].isin(processed_ids)].copy()\n",
    "    print(f\"Số lượng mẫu sau khi lọc (có cả ảnh và label): {len(labels_df_filtered)}\")\n",
    "\n",
    "    # Tạo dictionary từ ID sang label text (từ DataFrame đã lọc)\n",
    "    id_to_label = pd.Series(labels_df_filtered.label.values, index=labels_df_filtered.id).to_dict()\n",
    "\n",
    "    # Lặp qua các ID đã lọc để tạo list cuối cùng\n",
    "    for img_id in tqdm(labels_df_filtered['id'], desc=\"Khớp ảnh và nhãn\"):\n",
    "        img_filename = f\"{img_id}.png\" # Hoặc .jpg nếu có\n",
    "        img_path = os.path.join(processed_image_folder, img_filename)\n",
    "        # Kiểm tra lại lần nữa (dù đã lọc)\n",
    "        if os.path.exists(img_path):\n",
    "            image_paths.append(img_path)\n",
    "            text_labels.append(id_to_label[img_id])\n",
    "        else:\n",
    "             missing_images += 1 # Không nên xảy ra nếu lọc đúng\n",
    "\n",
    "    if missing_images > 0:\n",
    "        print(f\"Cảnh báo: {missing_images} ảnh có trong df_filtered nhưng không tìm thấy file!\")\n",
    "\n",
    "    return image_paths, text_labels"
   ],
   "id": "b00c6339cd0d289f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:54:12.236622Z",
     "start_time": "2025-04-05T13:54:11.845446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tải dữ liệu\n",
    "all_image_paths, all_text_labels = load_image_paths_and_text_labels(image_folder_processed, labels_df)\n",
    "\n",
    "if not all_image_paths:\n",
    "    print(\"Lỗi: Không tải được ảnh hoặc nhãn nào. Kiểm tra lại đường dẫn và file.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Đã tải thành công {len(all_image_paths)} cặp ảnh-nhãn.\")\n",
    "print(\"Ví dụ 5 nhãn đầu tiên:\", all_text_labels[:5])"
   ],
   "id": "62395cacb5ef0d5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số ID hợp lệ từ CSV: 7296\n",
      "Số ảnh tìm thấy trong thư mục đã xử lý: 7296\n",
      "Số lượng mẫu sau khi lọc (có cả ảnh và label): 7296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Khớp ảnh và nhãn: 100%|██████████| 7296/7296 [00:00<00:00, 21903.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tải thành công 7296 cặp ảnh-nhãn.\n",
      "Ví dụ 5 nhãn đầu tiên: ['Bản chất của thành công', 'Đã bao giờ bạn tự hỏi thành công là gì mà bao kẻ bỏ cả cuộc đời mình theo đuổi? Phải', 'chăng đó là kết quả hoàn hảo trong công việc, sự chính xác đến từng chi tiết? Hay đó', 'là cách nói khác của từ thành đạt, nghĩa là có được một cuộc sống giàu sang, được', 'mọi người nể phục? Vậy thì bạn hãy dành chút thời gian để lặng mình suy ngẫm.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:54:14.030493Z",
     "start_time": "2025-04-05T13:54:13.969971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI (Chia Train/Test cho dữ liệu HTR) ===\n",
    "# Đường dẫn lưu file train/test sau khi chia\n",
    "train_csv_path = os.path.join(data_dir, \"train_htr_lines.csv\")\n",
    "test_csv_path = os.path.join(data_dir, \"test_htr_lines.csv\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_paths, X_test_paths, y_train_text, y_test_text = train_test_split(\n",
    "    all_image_paths, all_text_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Số lượng mẫu train: {len(X_train_paths)}\")\n",
    "print(f\"Số lượng mẫu test: {len(X_test_paths)}\")\n",
    "\n",
    "try:\n",
    "    # Tạo DataFrame và lưu train set\n",
    "    train_data_to_save = pd.DataFrame({'image_path': X_train_paths, 'label': y_train_text})\n",
    "    train_data_to_save.to_csv(train_csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"Đã lưu tập train vào: {train_csv_path}\")\n",
    "\n",
    "    # Tạo DataFrame và lưu test set\n",
    "    test_data_to_save = pd.DataFrame({'image_path': X_test_paths, 'label': y_test_text})\n",
    "    test_data_to_save.to_csv(test_csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"Đã lưu tập test vào: {test_csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi lưu file train/test CSV: {e}\")\n"
   ],
   "id": "53f46100bc1a5a22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng mẫu train: 5836\n",
      "Số lượng mẫu test: 1460\n",
      "Đã lưu tập train vào: E:\\HANDS-VNOnDB\\train_htr_lines.csv\n",
      "Đã lưu tập test vào: E:\\HANDS-VNOnDB\\test_htr_lines.csv\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:55:23.380200Z",
     "start_time": "2025-04-05T13:55:23.308989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === THAY ĐỔI (Tạo bộ ký tự và mã hóa nhãn cho HTR) ===\n",
    "\n",
    "# Tìm tất cả các ký tự duy nhất từ tập train và test\n",
    "all_texts_for_vocab = y_train_text + y_test_text\n",
    "characters = set(char for text in all_texts_for_vocab for char in str(text))\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "# Thêm ký tự đặc biệt 'blank' cho CTC Loss (thường ở index 0)\n",
    "BLANK_TOKEN = '<blank>'\n",
    "if BLANK_TOKEN not in characters:\n",
    "    characters.insert(0, BLANK_TOKEN) # Đảm bảo blank ở vị trí 0\n",
    "\n",
    "print(f\"Tổng số ký tự (bao gồm blank): {len(characters)}\")\n",
    "# print(\"Bộ ký tự:\", \"\".join(characters)) # Có thể rất dài\n",
    "\n",
    "# Tạo từ điển ánh xạ\n",
    "char_to_int = {char: i for i, char in enumerate(characters)}\n",
    "int_to_char = {i: char for i, char in enumerate(characters)}\n",
    "\n",
    "# Số lượng lớp cho mô hình = số ký tự\n",
    "num_classes_htr = len(characters)\n",
    "print(f\"Số lớp đầu ra cho mô hình HTR: {num_classes_htr}\")\n",
    "\n",
    "# Hàm mã hóa text thành chuỗi số nguyên\n",
    "def encode_text(text, char_to_int_map):\n",
    "    return [char_to_int_map[char] for char in str(text) if char in char_to_int_map]\n",
    "\n",
    "# Mã hóa nhãn train và test\n",
    "y_train_encoded = [encode_text(text, char_to_int) for text in y_train_text]\n",
    "y_test_encoded = [encode_text(text, char_to_int) for text in y_test_text]\n",
    "\n",
    "# In thử vài mẫu đã mã hóa\n",
    "print(\"\\nVí dụ mã hóa:\")\n",
    "print(\"Nhãn gốc:\", y_train_text[0])\n",
    "print(\"Nhãn mã hóa:\", y_train_encoded[0])\n",
    "print(\"Giải mã lại:\", \"\".join([int_to_char[i] for i in y_train_encoded[0]]))"
   ],
   "id": "d836a8da784db0ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số ký tự (bao gồm blank): 162\n",
      "Số lớp đầu ra cho mô hình HTR: 162\n",
      "\n",
      "Ví dụ mã hóa:\n",
      "Nhãn gốc: Ngược lại, không có việc thì chúng tôi về, không phải tự nguyện xin về\n",
      "Nhãn mã hóa: [39, 57, 107, 150, 53, 1, 62, 108, 59, 9, 1, 61, 58, 93, 64, 57, 1, 53, 92, 1, 72, 59, 133, 53, 1, 70, 58, 89, 1, 53, 58, 96, 64, 57, 1, 70, 93, 59, 1, 72, 128, 9, 1, 61, 58, 93, 64, 57, 1, 66, 58, 110, 59, 1, 70, 158, 1, 64, 57, 71, 74, 133, 64, 1, 73, 59, 64, 1, 72, 128]\n",
      "Giải mã lại: Ngược lại, không có việc thì chúng tôi về, không phải tự nguyện xin về\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:55:55.062487Z",
     "start_time": "2025-04-05T13:55:54.864978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- THÊM CODE LƯU FILE ĐÃ MÃ HÓA ---\n",
    "import json\n",
    "from tqdm import tqdm # Đảm bảo tqdm đã được import\n",
    "print(\"\\nBắt đầu lưu file đã mã hóa và bản đồ ký tự...\")\n",
    "\n",
    "# Định nghĩa đường dẫn file lưu (cùng thư mục với train/test csv)\n",
    "encoded_train_path = os.path.join(data_dir, \"encoded_train_labels.json\")\n",
    "encoded_test_path = os.path.join(data_dir, \"encoded_test_labels.json\")\n",
    "charmap_path = os.path.join(data_dir, \"character_map.json\")\n",
    "\n",
    "try:\n",
    "    # Lưu y_train_encoded\n",
    "    with open(encoded_train_path, 'w', encoding='utf-8') as f_train:\n",
    "        json.dump(y_train_encoded, f_train)\n",
    "    print(f\"Đã lưu nhãn train đã mã hóa vào: {encoded_train_path}\")\n",
    "\n",
    "    # Lưu y_test_encoded\n",
    "    with open(encoded_test_path, 'w', encoding='utf-8') as f_test:\n",
    "        json.dump(y_test_encoded, f_test)\n",
    "    print(f\"Đã lưu nhãn test đã mã hóa vào: {encoded_test_path}\")\n",
    "\n",
    "    # Lưu cả hai bản đồ ký tự vào một file\n",
    "    # Chuyển key của int_to_char thành string để tương thích JSON\n",
    "    int_to_char_str_keys = {str(k): v for k, v in int_to_char.items()}\n",
    "    char_maps = {\n",
    "        'char_to_int': char_to_int,\n",
    "        'int_to_char': int_to_char_str_keys # Lưu phiên bản key là string\n",
    "    }\n",
    "    with open(charmap_path, 'w', encoding='utf-8') as f_map:\n",
    "        # indent=4 để dễ đọc file JSON hơn\n",
    "        # ensure_ascii=False để lưu đúng ký tự tiếng Việt\n",
    "        json.dump(char_maps, f_map, ensure_ascii=False, indent=4)\n",
    "    print(f\"Đã lưu bản đồ ký tự vào: {charmap_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi lưu file JSON đã mã hóa: {e}\")\n",
    "# --- KẾT THÚC CODE LƯU FILE ---"
   ],
   "id": "b164a1ac6ab11e57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bắt đầu lưu file đã mã hóa và bản đồ ký tự...\n",
      "Đã lưu nhãn train đã mã hóa vào: E:\\HANDS-VNOnDB\\encoded_train_labels.json\n",
      "Đã lưu nhãn test đã mã hóa vào: E:\\HANDS-VNOnDB\\encoded_test_labels.json\n",
      "Đã lưu bản đồ ký tự vào: E:\\HANDS-VNOnDB\\character_map.json\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:01:57.345469Z",
     "start_time": "2025-04-05T14:01:57.336470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transforms cho ảnh HTR\n",
    "htr_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), # Đảm bảo ảnh là 1 kênh màu\n",
    "    transforms.ToTensor(), # Chuyển sang Tensor và chuẩn hóa về [0, 1]\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Chuẩn hóa về [-1, 1] (phổ biến cho HTR)\n",
    "])"
   ],
   "id": "3f4c7433ec05ad",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:01:58.575438Z",
     "start_time": "2025-04-05T14:01:58.566438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDatasetHTR(Dataset):\n",
    "    def __init__(self, image_paths, encoded_labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.encoded_labels = encoded_labels # List các list số nguyên\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        encoded_label = self.encoded_labels[idx] # Lấy list số nguyên\n",
    "\n",
    "        try:\n",
    "            # Mở ảnh bằng Pillow trước khi transform\n",
    "            image = Image.open(img_path) # Không convert ở đây, để transform xử lý\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            # Trả về ảnh tensor và label là tensor số nguyên\n",
    "            return image, torch.tensor(encoded_label, dtype=torch.long)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi tải hoặc transform ảnh {img_path}: {e}\")\n",
    "            # Trả về None hoặc sample trống để collate_fn có thể xử lý\n",
    "            # Hoặc có thể bỏ qua sample này trong __init__\n",
    "            return None, None # Cần xử lý trong collate_fn"
   ],
   "id": "dffd829e2de0f9b7",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:02:00.673828Z",
     "start_time": "2025-04-05T14:02:00.664820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hàm collate_fn để xử lý batch có độ dài khác nhau\n",
    "# Cần xác định chiều rộng output của CNN (cnn_output_width)\n",
    "# ---- ƯỚC LƯỢNG CNN OUTPUT WIDTH ----\n",
    "# Với input W=256 và MobileNetV3 Small, sau các lớp stride=2, chiều rộng có thể giảm đi đáng kể.\n",
    "# VD: 256 -> 128 -> 64 -> 32 -> 16. Giả sử output là W=16 (Cần kiểm tra lại!)\n",
    "# Hoặc có thể không cần stride ở chiều rộng nhiều như vậy trong HTR.\n",
    "# Tạm thời ước lượng:\n",
    "CNN_OUTPUT_WIDTH = 64 # <--- GIÁ TRỊ NÀY RẤT QUAN TRỌNG, CẦN KIỂM TRA LẠI SAU KHI CÓ MODEL CNN\n",
    "\n",
    "def collate_fn_htr(batch):\n",
    "    # Lọc bỏ các sample bị lỗi (None)\n",
    "    batch = [item for item in batch if item[0] is not None]\n",
    "    if not batch:\n",
    "        return None, None, None, None # Trả về None nếu cả batch bị lỗi\n",
    "\n",
    "    images, labels = zip(*batch)\n",
    "\n",
    "    # Xếp chồng ảnh thành batch (N, C, H, W)\n",
    "    images = torch.stack(images, 0)\n",
    "\n",
    "    # Pad labels\n",
    "    label_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)\n",
    "    padded_labels = pad_sequence(labels, batch_first=True, padding_value=char_to_int[BLANK_TOKEN]) # Pad bằng blank token\n",
    "\n",
    "    # Tính toán input lengths cho CTCLoss (chiều dài sequence từ CNN output)\n",
    "    input_lengths = torch.full(size=(len(images),), fill_value=CNN_OUTPUT_WIDTH, dtype=torch.long)\n",
    "\n",
    "    return images, padded_labels, input_lengths, label_lengths"
   ],
   "id": "5b6d5a1e150f224c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T13:59:49.476995Z",
     "start_time": "2025-04-05T13:59:49.399984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Thử load dữ liệu từ file ---\n",
    "print(\"\\nKiểm tra và thử tải dữ liệu đã mã hóa từ file JSON...\")\n",
    "if os.path.exists(encoded_train_path) and \\\n",
    "   os.path.exists(encoded_test_path) and \\\n",
    "   os.path.exists(charmap_path):\n",
    "    try:\n",
    "        print(f\"Đang tải nhãn train từ: {encoded_train_path}\")\n",
    "        with open(encoded_train_path, 'r', encoding='utf-8') as f_train:\n",
    "            y_train_encoded = json.load(f_train)\n",
    "\n",
    "        print(f\"Đang tải nhãn test từ: {encoded_test_path}\")\n",
    "        with open(encoded_test_path, 'r', encoding='utf-8') as f_test:\n",
    "            y_test_encoded = json.load(f_test)\n",
    "\n",
    "        print(f\"Đang tải bản đồ ký tự từ: {charmap_path}\")\n",
    "        with open(charmap_path, 'r', encoding='utf-8') as f_map:\n",
    "            char_maps_loaded = json.load(f_map)\n",
    "            char_to_int = char_maps_loaded['char_to_int']\n",
    "            # Tái tạo int_to_char với key là integer từ char_to_int\n",
    "            int_to_char = {v: k for k, v in char_to_int.items()}\n",
    "\n",
    "        # Tính lại số lớp từ char_map đã load\n",
    "        num_classes_htr = len(char_to_int) # Hoặc len(int_to_char)\n",
    "        print(f\"Tải thành công! Số lớp: {num_classes_htr}\")\n",
    "        loaded_encoded_data = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi tải file JSON đã mã hóa: {e}. Sẽ tiến hành mã hóa lại.\")\n",
    "        # Reset biến về None để đảm bảo chạy mã hóa lại\n",
    "        y_train_encoded = None\n",
    "        y_test_encoded = None\n",
    "        char_to_int = None\n",
    "        int_to_char = None\n",
    "        num_classes_htr = None\n",
    "else:\n",
    "    print(\"Không tìm thấy file JSON đã mã hóa. Sẽ tiến hành mã hóa lại.\")\n"
   ],
   "id": "ef209608c43391dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kiểm tra và thử tải dữ liệu đã mã hóa từ file JSON...\n",
      "Đang tải nhãn train từ: E:\\HANDS-VNOnDB\\encoded_train_labels.json\n",
      "Đang tải nhãn test từ: E:\\HANDS-VNOnDB\\encoded_test_labels.json\n",
      "Đang tải bản đồ ký tự từ: E:\\HANDS-VNOnDB\\character_map.json\n",
      "Tải thành công! Số lớp: 162\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:04:51.653981Z",
     "start_time": "2025-04-05T14:04:51.642980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tạo Dataset và DataLoader mới\n",
    "train_dataset_htr = CustomDatasetHTR(X_train_paths, y_train_encoded, transform=htr_transform)\n",
    "test_dataset_htr = CustomDatasetHTR(X_test_paths, y_test_encoded, transform=htr_transform)"
   ],
   "id": "29ee94010cc96ad8",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:58:54.221636Z",
     "start_time": "2025-04-05T14:58:54.210629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Điều chỉnh batch_size tùy theo bộ nhớ GPU\n",
    "BATCH_SIZE = 32\n",
    "# NUM_WORKERS = 2 # Điều chỉnh số worker\n",
    "train_loader_htr = DataLoader(train_dataset_htr, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_htr, num_workers=0, pin_memory=True)\n",
    "test_loader_htr = DataLoader(test_dataset_htr, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_htr, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"\\nĐã tạo DataLoader với batch_size={BATCH_SIZE}\")\n",
    "# Kiểm tra thử một batch\n",
    "# try:\n",
    "#     images_batch, labels_batch, input_len_batch, label_len_batch = next(iter(train_loader_htr))\n",
    "#     print(\"Kích thước batch ảnh:\", images_batch.shape) # (N, C, H, W)\n",
    "#     print(\"Kích thước batch label (padded):\", labels_batch.shape) # (N, L_max)\n",
    "#     print(\"Kích thước input lengths:\", input_len_batch.shape) # (N,)\n",
    "#     print(\"Kích thước label lengths:\", label_len_batch.shape) # (N,)\n",
    "#     print(\"Input lengths sample:\", input_len_batch)\n",
    "# except Exception as e:\n",
    "#     print(f\"Lỗi khi lấy batch đầu tiên từ DataLoader: {e}\")"
   ],
   "id": "22dbe1b26bf9e16f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đã tạo DataLoader với batch_size=32\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:58:56.598050Z",
     "start_time": "2025-04-05T14:58:56.578028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Định nghĩa mô hình CRNN) ===\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, img_channels, num_classes, rnn_hidden_size=256, rnn_num_layers=2, leaky_relu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "         # Giảm số kênh CNN\n",
    "        nm = [32, 64, 128, 128, 256, 256, 256]# <-- Giảm nm\n",
    "        self.cnn_output_channels = nm[6] # <-- Cập nhật\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = img_channels if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module(f'conv{i}', nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization: cnn.add_module(f'batchnorm{i}', nn.BatchNorm2d(nOut))\n",
    "            if leaky_relu: cnn.add_module(f'relu{i}', nn.LeakyReLU(0.2, inplace=True))\n",
    "            else: cnn.add_module(f'relu{i}', nn.ReLU(True))\n",
    "\n",
    "        convRelu(0); cnn.add_module(f'pooling{0}', nn.MaxPool2d(2, 2)) # 64x16xW/2\n",
    "        convRelu(1); cnn.add_module(f'pooling{1}', nn.MaxPool2d(2, 2)) # 128x8xW/4\n",
    "        convRelu(2, True); convRelu(3); cnn.add_module(f'pooling{2}', nn.MaxPool2d((2, 2), (2, 1), (0, 1))) # 256x4x(W/4)+1 -> làm tròn W'/4\n",
    "        convRelu(4, True); convRelu(5); cnn.add_module(f'pooling{3}', nn.MaxPool2d((2, 2), (2, 1), (0, 1))) # 512x2xW'/4\n",
    "        convRelu(6, True) # 512x1xW'/4\n",
    "\n",
    "        self.cnn = cnn\n",
    "        self.rnn = nn.LSTM(self.cnn_output_channels, rnn_hidden_size, rnn_num_layers, bidirectional=True, batch_first=False)\n",
    "        self.fc = nn.Linear(rnn_hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN Part\n",
    "        features = self.cnn(x) # (N, C_out, 1, W_out)\n",
    "        N, C_out, H_out, W_out = features.size()\n",
    "        assert H_out == 1, f\"Expected height 1 after CNN, got {H_out}\"\n",
    "        features = features.squeeze(2) # (N, C_out, W_out)\n",
    "        # Map-to-Sequence\n",
    "        features = features.permute(2, 0, 1) # (W_out, N, C_out) - SeqLen = W_out\n",
    "        # RNN Part\n",
    "        rnn_output, _ = self.rnn(features) # (W_out, N, Hidden*2)\n",
    "        # FC Part\n",
    "        output = self.fc(rnn_output) # (W_out, N, NumClasses)\n",
    "        return output"
   ],
   "id": "4cf4671bb03fb122",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:58:58.885183Z",
     "start_time": "2025-04-05T14:58:58.845101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Khởi tạo model, loss, optimizer, checkpoint) ===\n",
    "# Kiểm tra device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nSử dụng device: {device}\")\n",
    "\n",
    "model_htr = CRNN(img_channels=1, num_classes=num_classes_htr)\n",
    "model_htr = model_htr.to(device)\n",
    "print(\"Khởi tạo mô hình CRNN thành công.\")\n",
    "\n",
    "# Thử forward 1 batch để kiểm tra kích thước output\n",
    "try:\n",
    "    model_htr.eval()\n",
    "    with torch.no_grad():\n",
    "         # Sử dụng context manager để tránh lỗi dataloader nếu num_workers > 0 trên Windows\n",
    "        with DataLoader(train_dataset_htr, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_htr, num_workers=0) as temp_loader:\n",
    "            test_batch = next(iter(temp_loader))\n",
    "            if test_batch[0] is not None:\n",
    "                images_batch_test = test_batch[0].to(device)\n",
    "                output_batch_test = model_htr(images_batch_test)\n",
    "                print(\"Kích thước output của mô hình (SeqLen, Batch, NumClasses):\", output_batch_test.shape)\n",
    "                # Kiểm tra SeqLen có khớp CNN_OUTPUT_WIDTH không\n",
    "                if output_batch_test.shape[0] != CNN_OUTPUT_WIDTH:\n",
    "                     print(f\"CẢNH BÁO: Output SeqLen {output_batch_test.shape[0]} KHÔNG khớp CNN_OUTPUT_WIDTH {CNN_OUTPUT_WIDTH}. Input lengths sẽ không chính xác!\")\n",
    "                else:\n",
    "                     print(\"Kiểm tra kích thước output thành công!\")\n",
    "            else:\n",
    "                print(\"Lỗi: Không thể lấy batch hợp lệ để kiểm tra model.\")\n",
    "    model_htr.train()\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi thử forward model: {e}\")"
   ],
   "id": "1f7fb0631218bd23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sử dụng device: cpu\n",
      "Khởi tạo mô hình CRNN thành công.\n",
      "Lỗi khi thử forward model: __enter__\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T06:24:45.874081Z",
     "start_time": "2025-04-06T06:24:45.863074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion_htr = nn.CTCLoss(blank=char_to_int[BLANK_TOKEN], reduction='mean', zero_infinity=True)\n",
    "optimizer_htr = optim.AdamW(model_htr.parameters(), lr=5e-2, weight_decay=4e-5)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_htr, 'min', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "CHECKPOINT_PATH_HTR = r\"G:\\Compvision Final\\pythonProject\\checkpoint_htr_line.pth\" # <--- Đổi tên checkpoint\n",
    "START_EPOCH_HTR = 0\n",
    "NUM_EPOCHS = 40\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Load checkpoint nếu có\n",
    "if os.path.exists(CHECKPOINT_PATH_HTR):\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH_HTR, map_location=device)\n",
    "        # Load char_to_int và int_to_char từ checkpoint nếu chúng tồn tại và khớp\n",
    "        # (Quan trọng nếu bạn thay đổi bộ ký tự giữa các lần chạy)\n",
    "        if 'char_to_int' in checkpoint and checkpoint['char_to_int'] == char_to_int:\n",
    "            print(\"Tải thành công char_to_int từ checkpoint.\")\n",
    "        else:\n",
    "            print(\"Cảnh báo: char_to_int trong checkpoint khác hoặc không tồn tại. Sử dụng bộ ký tự hiện tại.\")\n",
    "\n",
    "        model_htr.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer_htr.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        START_EPOCH_HTR = checkpoint.get('epoch', 0) + 1\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        train_losses = checkpoint.get('train_losses', [])\n",
    "        val_losses = checkpoint.get('val_losses', [])\n",
    "        print(f\"Đã tải checkpoint. Tiếp tục huấn luyện từ epoch {START_EPOCH_HTR}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi tải checkpoint: {e}. Bắt đầu huấn luyện từ đầu.\")\n",
    "        START_EPOCH_HTR = 0; best_val_loss = float('inf'); train_losses = []; val_losses = []\n",
    "else:\n",
    "    print(\"Không tìm thấy checkpoint. Bắt đầu huấn luyện từ đầu.\")"
   ],
   "id": "5cdcce9491561b05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Không tìm thấy checkpoint. Bắt đầu huấn luyện từ đầu.\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:59:29.869183Z",
     "start_time": "2025-04-05T14:59:29.852744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === KHÔNG THAY ĐỔI (Hàm giải mã Greedy) ===\n",
    "def decode_batch(outputs, int_to_char_map, blank_token_idx):\n",
    "    preds = torch.argmax(outputs.detach(), dim=2) # (SeqLen, Batch)\n",
    "    preds = preds.permute(1, 0) # (Batch, SeqLen)\n",
    "    decoded_texts = []\n",
    "    for pred_seq in preds:\n",
    "        text = \"\"\n",
    "        last_char_idx = -1\n",
    "        for idx in pred_seq:\n",
    "            idx_item = idx.item()\n",
    "            if idx_item == blank_token_idx or idx_item == last_char_idx:\n",
    "                last_char_idx = idx_item\n",
    "                continue\n",
    "            text += int_to_char_map.get(idx_item, '')\n",
    "            last_char_idx = idx_item\n",
    "        decoded_texts.append(text)\n",
    "    return decoded_texts"
   ],
   "id": "58dd77180caa99e7",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T06:24:41.614709900Z",
     "start_time": "2025-04-06T06:24:32.591883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\nBắt đầu huấn luyện từ epoch {START_EPOCH_HTR + 1} đến {NUM_EPOCHS} (BỎ QUA VALIDATION)\")\n",
    "\n",
    "for epoch in range(START_EPOCH_HTR, NUM_EPOCHS):\n",
    "    # --- Training Phase ---\n",
    "    model_htr.train()\n",
    "    running_loss = 0.0\n",
    "    num_train_samples = 0\n",
    "    train_progress_bar = tqdm(train_loader_htr, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\", unit=\"batch\")\n",
    "\n",
    "    for batch_data in train_progress_bar:\n",
    "        if batch_data[0] is None: continue\n",
    "\n",
    "        images, padded_labels, input_lengths, label_lengths = batch_data\n",
    "        current_batch_size = images.size(0)\n",
    "        num_train_samples += current_batch_size\n",
    "\n",
    "        images = images.to(device)\n",
    "        padded_labels = padded_labels.to(device)\n",
    "        input_lengths = input_lengths.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "\n",
    "        optimizer_htr.zero_grad()\n",
    "        outputs = model_htr(images)\n",
    "        log_probs = nn.functional.log_softmax(outputs, dim=2)\n",
    "\n",
    "        valid_input_lengths = torch.clamp(input_lengths, max=log_probs.shape[0])\n",
    "        valid_label_lengths = torch.clamp(label_lengths, min=1)\n",
    "        valid_indices = (valid_label_lengths > 0) & (valid_label_lengths <= valid_input_lengths)\n",
    "        if not valid_indices.any(): continue\n",
    "\n",
    "        log_probs_valid = log_probs[:, valid_indices, :]\n",
    "        padded_labels_valid = padded_labels[valid_indices]\n",
    "        valid_input_lengths_filtered = valid_input_lengths[valid_indices]\n",
    "        valid_label_lengths_filtered = valid_label_lengths[valid_indices]\n",
    "\n",
    "        try:\n",
    "            loss = criterion_htr(log_probs_valid, padded_labels_valid, valid_input_lengths_filtered, valid_label_lengths_filtered)\n",
    "            if torch.isnan(loss) or torch.isinf(loss): continue\n",
    "            loss.backward()\n",
    "            optimizer_htr.step()\n",
    "            running_loss += loss.item() * log_probs_valid.size(1)\n",
    "            train_progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nLỗi trong training step: {e}\")\n",
    "            continue\n",
    "\n",
    "    avg_train_loss = running_loss / num_train_samples if num_train_samples > 0 else 0.0\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train] Average Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # --- BỎ QUA HOÀN TOÀN VALIDATION PHASE ---\n",
    "\n",
    "    # Chỉ lưu checkpoint sau mỗi epoch (chứa model ở epoch đó)\n",
    "    checkpoint_data = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_htr.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_htr.state_dict(),\n",
    "        'char_to_int': char_to_int,\n",
    "        'int_to_char': int_to_char,\n",
    "        'train_losses': train_losses, # Chỉ còn train loss\n",
    "        # Bỏ val_losses và best_val_loss\n",
    "        'target_img_width': TARGET_IMG_WIDTH,\n",
    "        'target_img_height': TARGET_IMG_HEIGHT,\n",
    "        'cnn_output_width': CNN_OUTPUT_WIDTH\n",
    "    }\n",
    "    torch.save(checkpoint_data, CHECKPOINT_PATH_HTR)\n",
    "    print(f\"Checkpoint saved at epoch {epoch+1}\") # Có thể bỏ comment nếu muốn xem log lưu\n",
    "\n",
    "print(\"\\nHoàn thành huấn luyện (không có validation)!\")"
   ],
   "id": "a3afa748649b25f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bắt đầu huấn luyện từ epoch 36 đến 40 (BỎ QUA VALIDATION)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/40 [Train]:   6%|▌         | 11/183 [00:09<02:21,  1.22batch/s, loss=0.9304]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[78], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m num_train_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      8\u001B[0m train_progress_bar \u001B[38;5;241m=\u001B[39m tqdm(train_loader_htr, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mNUM_EPOCHS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m [Train]\u001B[39m\u001B[38;5;124m\"\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_data \u001B[38;5;129;01min\u001B[39;00m train_progress_bar:\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m batch_data[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     images, padded_labels, input_lengths, label_lengths \u001B[38;5;241m=\u001B[39m batch_data\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 708\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    714\u001B[0m ):\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    762\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    763\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 764\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    766\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[21], line 16\u001B[0m, in \u001B[0;36mCustomDatasetHTR.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     12\u001B[0m encoded_label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoded_labels[idx] \u001B[38;5;66;03m# Lấy list số nguyên\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;66;03m# Mở ảnh bằng Pillow trước khi transform\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_path\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# Không convert ở đây, để transform xử lý\u001B[39;00m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform:\n\u001B[0;32m     18\u001B[0m         image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image)\n",
      "File \u001B[1;32mG:\\Compvision Final\\pythonProject\\.venv\\lib\\site-packages\\PIL\\Image.py:3465\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3462\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(fp)\n\u001B[0;32m   3464\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3465\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3466\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3467\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:18:21.498915Z",
     "start_time": "2025-04-05T14:18:21.295093Z"
    }
   },
   "cell_type": "code",
   "source": "import jiwer",
   "id": "1d1af782d7667582",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T06:24:29.314158Z",
     "start_time": "2025-04-06T06:24:29.305152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_padded_labels(padded_labels, label_lengths, int_to_char_map):\n",
    "    \"\"\"\n",
    "    Chuyển đổi batch label đã được pad và tensor độ dài tương ứng\n",
    "    thành một list các chuỗi text gốc.\n",
    "\n",
    "    Args:\n",
    "        padded_labels (torch.Tensor): Tensor chứa các label đã mã hóa và pad.\n",
    "                                       Shape: (Batch, MaxLength)\n",
    "        label_lengths (torch.Tensor): Tensor chứa độ dài thực tế của mỗi label.\n",
    "                                      Shape: (Batch,)\n",
    "        int_to_char_map (dict): Từ điển ánh xạ từ index số nguyên sang ký tự.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List các chuỗi text gốc đã được giải mã.\n",
    "    \"\"\"\n",
    "    ground_truth_texts = []\n",
    "    # Chuyển tensor sang CPU nếu đang ở GPU để xử lý dễ hơn\n",
    "    padded_labels_cpu = padded_labels.cpu()\n",
    "    label_lengths_cpu = label_lengths.cpu()\n",
    "\n",
    "    for i in range(padded_labels_cpu.size(0)): # Lặp qua từng sample trong batch\n",
    "        label_len = label_lengths_cpu[i].item() # Lấy độ dài thực tế của label hiện tại\n",
    "\n",
    "        # Kiểm tra độ dài hợp lệ trước khi cắt tensor\n",
    "        if label_len <= 0:\n",
    "            # print(f\"Warning: Label length is {label_len} for sample index {i}. Decoding as empty string.\")\n",
    "            ground_truth_texts.append(\"\")\n",
    "            continue\n",
    "        # Đảm bảo label_len không vượt quá chiều dài đã pad\n",
    "        if label_len > padded_labels_cpu.shape[1]:\n",
    "             # print(f\"Warning: Label length {label_len} exceeds padded dimension {padded_labels_cpu.shape[1]} for sample {i}. Clamping.\")\n",
    "             label_len = padded_labels_cpu.shape[1] # Cắt bớt nếu độ dài không hợp lệ\n",
    "\n",
    "        # Lấy các indices thực tế của label (bỏ phần padding)\n",
    "        label_indices = padded_labels_cpu[i][:label_len].numpy() # Chuyển sang numpy array\n",
    "\n",
    "        # Chuyển các indices thành chuỗi ký tự\n",
    "        try:\n",
    "            # Dùng .get(idx, '') để tránh lỗi nếu gặp index không có trong map\n",
    "            text = \"\".join([int_to_char_map.get(idx, '') for idx in label_indices])\n",
    "            ground_truth_texts.append(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error decoding indices for sample {i}: {label_indices}. Error: {e}\")\n",
    "            ground_truth_texts.append(\"[DECODING ERROR]\") # Hoặc trả về chuỗi rỗng\n",
    "\n",
    "    return ground_truth_texts"
   ],
   "id": "3ce39bd18a834dad",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T15:03:54.298404Z",
     "start_time": "2025-04-05T15:03:48.774553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ... (Sau khi vòng lặp for epoch... huấn luyện kết thúc) ...\n",
    "\n",
    "print(\"\\n--- Bắt đầu đánh giá trên tập Test sau khi huấn luyện ---\")\n",
    "\n",
    "# 1. Load Model từ Checkpoint cuối cùng\n",
    "final_checkpoint_path = CHECKPOINT_PATH_HTR # Đường dẫn checkpoint cuối cùng bạn đã lưu\n",
    "load_path = final_checkpoint_path\n",
    "\n",
    "if os.path.exists(load_path):\n",
    "    print(f\"Đang tải model từ checkpoint cuối cùng: {load_path}\")\n",
    "    try:\n",
    "        checkpoint = torch.load(load_path, map_location=device)\n",
    "\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            print(\"Phát hiện file checkpoint đầy đủ.\")\n",
    "            state_dict_to_load = checkpoint['model_state_dict']\n",
    "            # Lấy lại char maps từ checkpoint là tốt nhất\n",
    "            if 'char_to_int' in checkpoint:\n",
    "                char_to_int = checkpoint['char_to_int']\n",
    "                print(\"Đã tải char_to_int từ checkpoint.\")\n",
    "            else:\n",
    "                print(\"Cảnh báo: Không tìm thấy char_to_int trong checkpoint. Sử dụng map hiện tại.\")\n",
    "            if 'int_to_char' in checkpoint:\n",
    "                int_to_char = checkpoint['int_to_char']\n",
    "                print(\"Đã tải int_to_char từ checkpoint.\")\n",
    "            else:\n",
    "                 print(\"Cảnh báo: Không tìm thấy int_to_char trong checkpoint. Sử dụng map hiện tại.\")\n",
    "\n",
    "            num_classes_loaded = len(char_to_int)\n",
    "            print(f\"Số lớp được tải từ checkpoint: {num_classes_loaded}\")\n",
    "\n",
    "            # Lấy BLANK_TOKEN_INDEX từ char_to_int đã load\n",
    "            if BLANK_TOKEN in char_to_int:\n",
    "                BLANK_TOKEN_INDEX = char_to_int[BLANK_TOKEN]\n",
    "            else:\n",
    "                print(f\"Cảnh báo: '{BLANK_TOKEN}' không có trong char_to_int đã load. Dùng index 0.\")\n",
    "                BLANK_TOKEN_INDEX = 0\n",
    "\n",
    "        else:\n",
    "            print(f\"Lỗi: File {load_path} không chứa 'model_state_dict'.\")\n",
    "            exit()\n",
    "\n",
    "        # Khởi tạo cấu trúc model với số lớp đúng\n",
    "        model_to_evaluate = CRNN(img_channels=1, num_classes=num_classes_loaded).to(device)\n",
    "        model_to_evaluate.load_state_dict(state_dict_to_load)\n",
    "        print(\"Tải trọng số model để đánh giá thành công.\")\n",
    "        model_to_evaluate.eval() # Chuyển sang chế độ đánh giá\n",
    "\n",
    "        # 2. Chuẩn bị DataLoader cho tập Test\n",
    "        if 'test_loader_htr' not in locals() or test_loader_htr is None:\n",
    "             print(\"Lỗi: test_loader_htr chưa được tạo hoặc không hợp lệ.\")\n",
    "             exit()\n",
    "\n",
    "        # 3. Chạy vòng lặp đánh giá\n",
    "        total_wer_info_final = {'hits': 0, 'substitutions': 0, 'deletions': 0, 'insertions': 0, 'words': 0}\n",
    "        total_cer_info_final = {'hits': 0, 'substitutions': 0, 'deletions': 0, 'insertions': 0, 'chars': 0}\n",
    "        evaluation_progress_bar = tqdm(test_loader_htr, desc=\"Evaluating Test Set\", unit=\"batch\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_data in evaluation_progress_bar:\n",
    "                if batch_data[0] is None: continue\n",
    "\n",
    "                images, padded_labels, input_lengths, label_lengths = batch_data\n",
    "                images = images.to(device)\n",
    "                padded_labels = padded_labels.to(device)\n",
    "                label_lengths = label_lengths.to(device)\n",
    "\n",
    "                # 4. Dự đoán và Giải mã\n",
    "                outputs = model_to_evaluate(images)\n",
    "                predicted_texts = decode_batch(outputs.cpu(), int_to_char, BLANK_TOKEN_INDEX)\n",
    "\n",
    "                # 5. Lấy nhãn gốc\n",
    "                ground_truth_texts = decode_padded_labels(padded_labels, label_lengths, int_to_char)\n",
    "\n",
    "                # 6. Tính toán và Tích lũy\n",
    "                try:\n",
    "                    # --- Tính WER (Giữ nguyên) ---\n",
    "                    wer_measures = jiwer.compute_measures(ground_truth_texts, predicted_texts)\n",
    "                    total_wer_info_final['substitutions'] += wer_measures['substitutions']\n",
    "                    total_wer_info_final['deletions'] += wer_measures['deletions']\n",
    "                    total_wer_info_final['insertions'] += wer_measures['insertions']\n",
    "                    total_wer_info_final['hits'] += wer_measures['hits']\n",
    "                    total_wer_info_final['words'] += sum(len(t.split()) for t in ground_truth_texts if t)\n",
    "\n",
    "                    # --- Tính CER bằng Workaround ---\n",
    "                    # Biến đổi chuỗi: thêm khoảng trắng giữa các ký tự\n",
    "                    gt_chars = [\" \".join(list(t)) if t else \"\" for t in ground_truth_texts]\n",
    "                    pred_chars = [\" \".join(list(p)) if p else \"\" for p in predicted_texts]\n",
    "\n",
    "                    # Gọi compute_measures trên chuỗi đã biến đổi (KHÔNG dùng char_level=True)\n",
    "                    # jiwer sẽ coi mỗi ký tự là một \"từ\"\n",
    "                    cer_measures_workaround = jiwer.compute_measures(gt_chars, pred_chars)\n",
    "\n",
    "                    # Cộng dồn lỗi ký tự từ kết quả workaround\n",
    "                    total_cer_info_final['substitutions'] += cer_measures_workaround['substitutions']\n",
    "                    total_cer_info_final['deletions'] += cer_measures_workaround['deletions']\n",
    "                    total_cer_info_final['insertions'] += cer_measures_workaround['insertions']\n",
    "                    total_cer_info_final['hits'] += cer_measures_workaround['hits']\n",
    "\n",
    "                    # Cộng dồn TỔNG SỐ KÝ TỰ GỐC (quan trọng!)\n",
    "                    total_cer_info_final['chars'] += sum(len(t) for t in ground_truth_texts if t)\n",
    "                    # -----------------------------\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Thay đổi thông báo lỗi để rõ ràng hơn\n",
    "                    print(f\"\\nLỗi khi tính WER/CER (workaround) với jiwer: {e}\")\n",
    "\n",
    "\n",
    "        # 7. Tính WER/CER cuối cùng\n",
    "        final_word_errors = total_wer_info_final['substitutions'] + total_wer_info_final['deletions'] + total_wer_info_final['insertions']\n",
    "        final_wer = final_word_errors / total_wer_info_final['words'] if total_wer_info_final['words'] > 0 else float('inf')\n",
    "\n",
    "        # Tính CER từ các thành phần lỗi đã cộng dồn (theo workaround)\n",
    "        final_char_errors = total_cer_info_final['substitutions'] + total_cer_info_final['deletions'] + total_cer_info_final['insertions']\n",
    "        # Tính CER dựa trên tổng số ký tự gốc đã đếm\n",
    "        final_cer = final_char_errors / total_cer_info_final['chars'] if total_cer_info_final['chars'] > 0 else float('inf')\n",
    "\n",
    "        print(\"\\n--- Kết quả đánh giá cuối cùng trên tập Test ---\")\n",
    "        print(f\"Word Error Rate (WER): {final_wer:.4f}\")\n",
    "        print(f\"Character Error Rate (CER): {final_cer:.4f}\") # CER sẽ không còn là inf nếu tính đúng\n",
    "        print(f\"(Dựa trên {total_wer_info_final['words']} từ và {total_cer_info_final['chars']} ký tự gốc)\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file checkpoint tại {load_path} để đánh giá.\")\n",
    "    except KeyError as e:\n",
    "         print(f\"Lỗi: Key không tìm thấy trong checkpoint khi tải ({e}). File checkpoint có thể bị lỗi hoặc không đúng định dạng.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định trong quá trình đánh giá cuối cùng: {e}\")\n",
    "else:\n",
    "    print(f\"Không tìm thấy checkpoint tại {load_path} để thực hiện đánh giá cuối cùng.\")\n",
    "\n",
    "print(\"\\nScript HTR hoàn tất.\")"
   ],
   "id": "e1bef3fafaa0972e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bắt đầu đánh giá trên tập Test sau khi huấn luyện ---\n",
      "Đang tải model từ checkpoint cuối cùng: G:\\Compvision Final\\pythonProject\\checkpoint_htr_line.pth\n",
      "Phát hiện file checkpoint đầy đủ.\n",
      "Đã tải char_to_int từ checkpoint.\n",
      "Đã tải int_to_char từ checkpoint.\n",
      "Số lớp được tải từ checkpoint: 162\n",
      "Tải trọng số model để đánh giá thành công.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set: 100%|██████████| 46/46 [00:05<00:00,  8.46batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Kết quả đánh giá cuối cùng trên tập Test ---\n",
      "Word Error Rate (WER): 0.9977\n",
      "Character Error Rate (CER): 0.6938\n",
      "(Dựa trên 22737 từ và 98048 ký tự gốc)\n",
      "\n",
      "Script HTR hoàn tất.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4ad53d2cdc5409cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
